{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"starlite-saqlalchemy \u00b6 An API application pattern standing on the shoulders of: Starlite : \"...a light, opinionated and flexible ASGI API framework built on top of pydantic\". SQLAlchemy 2.0 : \"The Python SQL Toolkit and Object Relational Mapper\". SAQ : \"...a simple and performant job queueing framework built on top of asyncio and redis\". Structlog : \"...makes logging in Python faster, less painful, and more powerful\". Usage Example \u00b6 Simple Example \"\"\"The minimal Starlite/starlite-saqlalchemy application.\"\"\" from starlite import Starlite , get from starlite_saqlalchemy import ConfigureApp @get ( \"/example\" ) def example_handler () -> dict : \"\"\"Hello, world!\"\"\" return { \"hello\" : \"world\" } app = Starlite ( route_handlers = [ example_handler ], on_app_init = [ ConfigureApp ()]) Check out the Usage section to see all the features this configures on the application! Pattern \u00b6 sequenceDiagram Client ->> Controller: Inbound request data Controller ->> Service: Invoke service with data validated by DTO Service ->> Repository: View or modify the collection Repository ->> Service: Detached SQLAlchemy instance(s) Service ->> Queue: Optionally enqueue an async callback Service ->> Controller: Outbound data Controller ->> Client: Serialize via DTO Queue ->> Worker: Worker invoked Worker ->> Service: Makes async callback Request data is deserialized and validated by Starlite before it is received by controller. Controller invokes relevant service object method and waits for response. Service method handles business logic of the request and optionally triggers an asynchronous callback. Service method returns to controller and response is made to client. Async worker makes callback to service object where any async tasks can be performed. Depending on architecture, this may not be the same instance of the application that handled the request. Motivation \u00b6 A modern, production-ready API has a lot of components. Starlite, the backbone of this library, exposes a plethora of features and functionality that requires some amount of boilerplate and configuration that must be carried from one implementation of an application to the next. starlite-saqlalchemy is an example of how Starlite's on_app_init hook can be utilized to build application configuration libraries that support streamlining the application development process. However, more than just an example, this library intends to be an opinionated resource to support the efficient, and consistent rollout of production ready APIs built on top of Starlite. Use this library if the stack and design decisions suit your taste. If there are improvements or generalizations that could be made to the library to support your use case, we'd love to hear about them. Open an issue or start a discussion . Backward compatibility and releases \u00b6 This project follows semantic versioning, and we use semantic releases in our toolchain. This means that bug fixes and new features will find there way into a release as soon they hit the main branch, and if we break something, we'll bump the major version number. However, until we hit v1.0, there will be breaking changes between minor versions, but v1.0 is close!","title":"starlite-saqlalchemy"},{"location":"#starlite-saqlalchemy","text":"An API application pattern standing on the shoulders of: Starlite : \"...a light, opinionated and flexible ASGI API framework built on top of pydantic\". SQLAlchemy 2.0 : \"The Python SQL Toolkit and Object Relational Mapper\". SAQ : \"...a simple and performant job queueing framework built on top of asyncio and redis\". Structlog : \"...makes logging in Python faster, less painful, and more powerful\".","title":"starlite-saqlalchemy"},{"location":"#usage-example","text":"Simple Example \"\"\"The minimal Starlite/starlite-saqlalchemy application.\"\"\" from starlite import Starlite , get from starlite_saqlalchemy import ConfigureApp @get ( \"/example\" ) def example_handler () -> dict : \"\"\"Hello, world!\"\"\" return { \"hello\" : \"world\" } app = Starlite ( route_handlers = [ example_handler ], on_app_init = [ ConfigureApp ()]) Check out the Usage section to see all the features this configures on the application!","title":"Usage Example"},{"location":"#pattern","text":"sequenceDiagram Client ->> Controller: Inbound request data Controller ->> Service: Invoke service with data validated by DTO Service ->> Repository: View or modify the collection Repository ->> Service: Detached SQLAlchemy instance(s) Service ->> Queue: Optionally enqueue an async callback Service ->> Controller: Outbound data Controller ->> Client: Serialize via DTO Queue ->> Worker: Worker invoked Worker ->> Service: Makes async callback Request data is deserialized and validated by Starlite before it is received by controller. Controller invokes relevant service object method and waits for response. Service method handles business logic of the request and optionally triggers an asynchronous callback. Service method returns to controller and response is made to client. Async worker makes callback to service object where any async tasks can be performed. Depending on architecture, this may not be the same instance of the application that handled the request.","title":"Pattern"},{"location":"#motivation","text":"A modern, production-ready API has a lot of components. Starlite, the backbone of this library, exposes a plethora of features and functionality that requires some amount of boilerplate and configuration that must be carried from one implementation of an application to the next. starlite-saqlalchemy is an example of how Starlite's on_app_init hook can be utilized to build application configuration libraries that support streamlining the application development process. However, more than just an example, this library intends to be an opinionated resource to support the efficient, and consistent rollout of production ready APIs built on top of Starlite. Use this library if the stack and design decisions suit your taste. If there are improvements or generalizations that could be made to the library to support your use case, we'd love to hear about them. Open an issue or start a discussion .","title":"Motivation"},{"location":"#backward-compatibility-and-releases","text":"This project follows semantic versioning, and we use semantic releases in our toolchain. This means that bug fixes and new features will find there way into a release as soon they hit the main branch, and if we break something, we'll bump the major version number. However, until we hit v1.0, there will be breaking changes between minor versions, but v1.0 is close!","title":"Backward compatibility and releases"},{"location":"async_worker/","text":"Async Worker \u00b6 Integrated asynchronous worker for processing background jobs. Pattern is built on SAQ ( why SAQ? ) Service object integration \u00b6 You can leverage the async worker without needing to know anything specific about the worker implementation. The generic Service object includes a method that allows you to enqueue a background task. Example \u00b6 Let's add a background task that sends an email whenever a new Author is created. from typing import Any from starlite_saqlalchemy import service from starlite_saqlalchemy.repository.sqlalchemy import SQLAlchemyRepository from domain.authors import Author , ReadDTO class Repository ( SQLAlchemyRepository [ Author ]): model_type = Author class Service ( service . RepositoryService [ Author ]): \"\"\"Author service object.\"\"\" repository_type = Repository async def create ( self , data : Author ) -> Author : created = await super () . create ( data ) await self . enqueue_background_task ( \"send_author_created_email\" , raw_author = ReadDTO . from_orm ( created ) . dict () ) return created async def send_author_created_email ( self , raw_author : dict [ str , Any ]) -> None : \"\"\"Logic here to send the email.\"\"\" Don't block the event loop \u00b6 It is important to remember that this worker runs on the same event loop as the application itself, so be mindful that the operations you do in background tasks aren't blocking the loop. If you need to do computationally heavy work in background tasks, a better pattern would be to use a something like Honcho to start an SAQ worker in a different process to the Starlite application, and run your app in a multicore environment. Why SAQ \u00b6 I like that it leverages BLMOVE instead of polling to wait for jobs: see Pattern: Reliable queue . SAQ also make a direct comparison to ARQ in their README , so I'll let that speak for itself: SAQ is heavily inspired by ARQ but has several enhancements. Avoids polling by leveraging BLMOVE or RPOPLPUSH and NOTIFY i. SAQ has much lower latency than ARQ, with delays of < 5ms. ARQ's default polling frequency is 0.5 seconds ii. SAQ is up to 8x faster than ARQ Web interface for monitoring queues and workers Heartbeat monitor for abandoned jobs More robust failure handling i. Storage of stack traces ii. Sweeping stuck jobs iii. Handling of cancelled jobs different from failed jobs (machine redeployments) Before and after job hooks Easily run multiple workers to leverage more cores","title":"Async Worker"},{"location":"async_worker/#async-worker","text":"Integrated asynchronous worker for processing background jobs. Pattern is built on SAQ ( why SAQ? )","title":"Async Worker"},{"location":"async_worker/#service-object-integration","text":"You can leverage the async worker without needing to know anything specific about the worker implementation. The generic Service object includes a method that allows you to enqueue a background task.","title":"Service object integration"},{"location":"async_worker/#example","text":"Let's add a background task that sends an email whenever a new Author is created. from typing import Any from starlite_saqlalchemy import service from starlite_saqlalchemy.repository.sqlalchemy import SQLAlchemyRepository from domain.authors import Author , ReadDTO class Repository ( SQLAlchemyRepository [ Author ]): model_type = Author class Service ( service . RepositoryService [ Author ]): \"\"\"Author service object.\"\"\" repository_type = Repository async def create ( self , data : Author ) -> Author : created = await super () . create ( data ) await self . enqueue_background_task ( \"send_author_created_email\" , raw_author = ReadDTO . from_orm ( created ) . dict () ) return created async def send_author_created_email ( self , raw_author : dict [ str , Any ]) -> None : \"\"\"Logic here to send the email.\"\"\"","title":"Example"},{"location":"async_worker/#dont-block-the-event-loop","text":"It is important to remember that this worker runs on the same event loop as the application itself, so be mindful that the operations you do in background tasks aren't blocking the loop. If you need to do computationally heavy work in background tasks, a better pattern would be to use a something like Honcho to start an SAQ worker in a different process to the Starlite application, and run your app in a multicore environment.","title":"Don't block the event loop"},{"location":"async_worker/#why-saq","text":"I like that it leverages BLMOVE instead of polling to wait for jobs: see Pattern: Reliable queue . SAQ also make a direct comparison to ARQ in their README , so I'll let that speak for itself: SAQ is heavily inspired by ARQ but has several enhancements. Avoids polling by leveraging BLMOVE or RPOPLPUSH and NOTIFY i. SAQ has much lower latency than ARQ, with delays of < 5ms. ARQ's default polling frequency is 0.5 seconds ii. SAQ is up to 8x faster than ARQ Web interface for monitoring queues and workers Heartbeat monitor for abandoned jobs More robust failure handling i. Storage of stack traces ii. Sweeping stuck jobs iii. Handling of cancelled jobs different from failed jobs (machine redeployments) Before and after job hooks Easily run multiple workers to leverage more cores","title":"Why SAQ"},{"location":"config/","text":"Configuring the application \u00b6 Configuration is via environment. Minimal .env \u00b6 Minimal .env NAME=tmpl-starlite-saqlalchemy DB_URL=postgresql+asyncpg://postgres:mysecretpassword@localhost:5432/postgres1 OPENAPI_CONTACT_EMAIL=peter.github@proton.me OPENAPI_CONTACT_NAME=\"Peter Schutt\" OPENAPI_TITLE=\"Template starlite-saqlalchemy Application\" OPENAPI_VERSION=1.0.0 REDIS_URL=redis://localhost:6379/0 Local Development \u00b6 Structured logs are nice when sending our logs through to some ingestion service, however, not so nice for local development. set ENVIRONMENT=local in your local .env file for a nicer local development experience (we implement this structlog pattern for you!). Full .env \u00b6 Example .env # App BUILD_NUMBER= CHECK_DB_READY=true CHECK_REDIS_READY=true DEBUG=true ENVIRONMENT=local NAME=my-starlite-app # API API_CACHE_EXPIRATION=60 API_DB_SESSION_DEPENDENCY_KEY=db_session API_DEFAULT_PAGINATION_LIMIT=100 API_DTO_INFO_KEY=dto API_HEALTH_PATH=/health # Log LOG_EXCLUDE_PATHS=\"\\A(?!x)x\" LOG_HTTP_EVENT=\"HTTP\" LOG_INCLUDE_COMPRESSED_BODY=false LOG_LEVEL=20 LOG_OBFUSCATE_COOKIES='[\"session\"]' LOG_OBFUSCATE_HEADERS='[\"Authorization\",\"X-API-KEY\"]' LOG_REQUEST_FIELDS='[\"path\",\"method\",\"content_type\",\"headers\",\"cookies\",\"query\",\"path_params\",\"body\"]' LOG_RESPONSE_FIELDS='[\"status_code\",\"cookies\",\"headers\",\"body\"]' LOG_WORKER_EVENT=\"Worker\" LOG_SAQ_LEVEL=30 LOG_SQLALCHEMY_LEVEL=30 LOG_UVICORN_ACCESS_LEVEL=30 LOG_UVICORN_ERROR_LEVEL=30 # OpenAPI OPENAPI_CONTACT_EMAIL=some_human@email.com OPENAPI_CONTACT_NAME=\"Some Human\" OPENAPI_TITLE=\"My Starlite App\" OPENAPI_VERSION=1.0.0 # Database DB_ECHO=false DB_ECHO_POOL=false DB_POOL_DISABLE=false DB_POOL_MAX_OVERFLOW=10 DB_POOL_SIZE=5 DB_POOL_TIMEOUT=30 DB_URL=postgresql+asyncpg://postgres:mysecretpassword@pg.db.local:5432/db # Redis REDIS_URL=redis://cache.local:6379/0 # Sentry SENTRY_DSN= SENTRY_TRACES_SAMPLE_RATE=0.0001 # Server SERVER_APP_LOC=app.main:app_factory SERVER_APP_LOC_IS_FACTORY=true SERVER_HOST=localhost SERVER_KEEPALIVE=65 SERVER_PORT=8000 SERVER_RELOAD=false SERVER_RELOAD_DIRS='[]' # Worker WORKER_JOB_TIMEOUT=10 WORKER_JOB_HEARTBEAT=0 WORKER_JOB_RETRIES=10 WORKER_JOB_TTL=600 WORKER_JOB_RETRY_DELAY=1.0 WORKER_JOB_RETRY_BACKOFF=60","title":"Configuration"},{"location":"config/#configuring-the-application","text":"Configuration is via environment.","title":"Configuring the application"},{"location":"config/#minimal-env","text":"Minimal .env NAME=tmpl-starlite-saqlalchemy DB_URL=postgresql+asyncpg://postgres:mysecretpassword@localhost:5432/postgres1 OPENAPI_CONTACT_EMAIL=peter.github@proton.me OPENAPI_CONTACT_NAME=\"Peter Schutt\" OPENAPI_TITLE=\"Template starlite-saqlalchemy Application\" OPENAPI_VERSION=1.0.0 REDIS_URL=redis://localhost:6379/0","title":"Minimal .env"},{"location":"config/#local-development","text":"Structured logs are nice when sending our logs through to some ingestion service, however, not so nice for local development. set ENVIRONMENT=local in your local .env file for a nicer local development experience (we implement this structlog pattern for you!).","title":"Local Development"},{"location":"config/#full-env","text":"Example .env # App BUILD_NUMBER= CHECK_DB_READY=true CHECK_REDIS_READY=true DEBUG=true ENVIRONMENT=local NAME=my-starlite-app # API API_CACHE_EXPIRATION=60 API_DB_SESSION_DEPENDENCY_KEY=db_session API_DEFAULT_PAGINATION_LIMIT=100 API_DTO_INFO_KEY=dto API_HEALTH_PATH=/health # Log LOG_EXCLUDE_PATHS=\"\\A(?!x)x\" LOG_HTTP_EVENT=\"HTTP\" LOG_INCLUDE_COMPRESSED_BODY=false LOG_LEVEL=20 LOG_OBFUSCATE_COOKIES='[\"session\"]' LOG_OBFUSCATE_HEADERS='[\"Authorization\",\"X-API-KEY\"]' LOG_REQUEST_FIELDS='[\"path\",\"method\",\"content_type\",\"headers\",\"cookies\",\"query\",\"path_params\",\"body\"]' LOG_RESPONSE_FIELDS='[\"status_code\",\"cookies\",\"headers\",\"body\"]' LOG_WORKER_EVENT=\"Worker\" LOG_SAQ_LEVEL=30 LOG_SQLALCHEMY_LEVEL=30 LOG_UVICORN_ACCESS_LEVEL=30 LOG_UVICORN_ERROR_LEVEL=30 # OpenAPI OPENAPI_CONTACT_EMAIL=some_human@email.com OPENAPI_CONTACT_NAME=\"Some Human\" OPENAPI_TITLE=\"My Starlite App\" OPENAPI_VERSION=1.0.0 # Database DB_ECHO=false DB_ECHO_POOL=false DB_POOL_DISABLE=false DB_POOL_MAX_OVERFLOW=10 DB_POOL_SIZE=5 DB_POOL_TIMEOUT=30 DB_URL=postgresql+asyncpg://postgres:mysecretpassword@pg.db.local:5432/db # Redis REDIS_URL=redis://cache.local:6379/0 # Sentry SENTRY_DSN= SENTRY_TRACES_SAMPLE_RATE=0.0001 # Server SERVER_APP_LOC=app.main:app_factory SERVER_APP_LOC_IS_FACTORY=true SERVER_HOST=localhost SERVER_KEEPALIVE=65 SERVER_PORT=8000 SERVER_RELOAD=false SERVER_RELOAD_DIRS='[]' # Worker WORKER_JOB_TIMEOUT=10 WORKER_JOB_HEARTBEAT=0 WORKER_JOB_RETRIES=10 WORKER_JOB_TTL=600 WORKER_JOB_RETRY_DELAY=1.0 WORKER_JOB_RETRY_BACKOFF=60","title":"Full .env"},{"location":"dto/","text":"DTOs \u00b6 What are DTOs? \u00b6 DTO stands for \"Data Transfer Object\". They are the filter through which data is accepted into, and output from the application. Why DTOs? \u00b6 Data that is modifiable by clients, and that should be read by clients is often only a subset of the attributes that make up a domain object. For example, lets say we have an internal representation of an Author that looks like this: { \"id\" : \"97108ac1-ffcb-411d-8b1e-d9183399f63b\" , \"name\" : \"Agatha Christie\" , \"dob\" : \"1890-9-15\" , \"created\" : \"2022-11-27T01:58:00\" , \"updated\" : \"2022-11-27T01:59:00\" } Of those attributes, values for \"id\", \"created\" and \"updated\" are internally generated, and should not be available to be modified by clients of our application. This is where a DTO comes in. We create a type to validate user input that will only allow values for \"name\" and \"dob\" from clients, for example: { \"name\" : \"Agatha Christie\" , \"dob\" : \"1890-9-15\" } dto.FromMapped \u00b6 Generate pydantic models from SQLAlchemy ORM models. Mark fields as \"read-only\" or \"private\" to control inclusion of fields on DTO models. Automatically infer defaults, and default factories from the SQLAlchemy column definitions. The dto.FromMapped type allows us to use our domain models, which are defined as SQLAlchemy ORM types, to generate DTOs. Here's a quick example. Simple Example from __future__ import annotations from datetime import date , datetime from typing import Annotated from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto class Base ( DeclarativeBase ): \"\"\"ORM base class. All SQLAlchemy ORM models must inherit from DeclarativeBase. We also define some common columns that we want to be present on every model in our domain. \"\"\" id : Mapped [ int ] = mapped_column ( primary_key = True ) created : Mapped [ datetime ] updated : Mapped [ datetime ] class Author ( Base ): \"\"\"A domain model. In addition to the columns defined on `Base` we have \"name\" and \"dob\". \"\"\" __tablename__ = \"authors\" name : Mapped [ str ] dob : Mapped [ date ] # This creates a DTO, which is simply a Pydantic model that inherits # from our special `FromMapped` subclass. We call it \"WriteDTO\" as it # is the model that we'll use to parse client data as they try to # \"write\" to (that is, create or update) authors in our domain. WriteDTO = dto . FromMapped [ Annotated [ Author , \"write\" ]] # we can inspect the fields that are available on the DTO print ( WriteDTO . __fields__ ) # { # \"id\": ModelField(name=\"id\", type=int, required=True), # \"created\": ModelField(name=\"created\", type=datetime, required=True), # \"updated\": ModelField(name=\"updated\", type=datetime, required=True), # \"name\": ModelField(name=\"name\", type=str, required=True), # \"dob\": ModelField(name=\"dob\", type=date, required=True), # } Read the comments in the example for a description of everything that is going on, however notice that the fields on our DTO type include \"id\", \"created\", and \"updated\" - fields that should not be modifiable by clients. Let's have another go: Simple Example with Read Only Fields from __future__ import annotations from datetime import date , datetime from typing import Annotated from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto class Base ( DeclarativeBase ): \"\"\"ORM base class. Using the dto.field() function, we've annotated that these columns are read-only. \"\"\" id : Mapped [ int ] = mapped_column ( primary_key = True , info = dto . field ( \"read-only\" )) created : Mapped [ datetime ] = mapped_column ( info = dto . field ( \"read-only\" )) updated : Mapped [ datetime ] = mapped_column ( info = dto . field ( \"read-only\" )) class Author ( Base ): \"\"\"Domain object.\"\"\" __tablename__ = \"authors\" name : Mapped [ str ] dob : Mapped [ date ] WriteDTO = dto . FromMapped [ Annotated [ Author , \"write\" ]] # now when we inspect our fields, we can see that our \"write\" purposed # DTO does not include any of the fields that we marked as \"read-only\" # fields. print ( WriteDTO . __fields__ ) # { # \"name\": ModelField(name=\"name\", type=str, required=True), # \"dob\": ModelField(name=\"dob\", type=date, required=True), # } That's better! Now, we'll only parse \"name\" and \"dob\" fields out of client input. Configuring generated DTOs \u00b6 Th two main factors that influence how a DTO is generated for a given domain model are: The modifiability and privacy of the individual attributes of the domain model. The purpose of the DTO, is it to be used to parse and validate inbound client data, or to serialize outbound data. Configuring DTO Fields \u00b6 dto.DTOField \u00b6 This is the object that we use to configure DTO fields. To use the dto.DTOField object assign a dict to the mapped_column() or relationship info parameter, with the \"dto\" key and an instance of dto.DTOField as value, for example col: Mapped[str] = mapped_column(info={\"dto\": dto.DTOField(...)}) . The dto.DTOField object supports marking fields as \"read-only\" or \"private\" , setting an explicit pydantic FieldInfo and type, and setting validators for the field. The easiest way to configure a DTO field is through the dto.field() function. dto.field() \u00b6 The dto.field() function creates an info dict for us, setting values on an dto.DTOField instance as appropriate. For example, the following are identical: col: Mapped[str] = mapped_column(info={\"dto\": dto.DTOField(mark=dto.Mark.PRIVATE)}) col: Mapped[str] = mapped_column(info=dto.field(\"private\")) field() supports the same arguments as DTOField , however it will also coerce string values for mark to the appropriate enum. dto.Mark \u00b6 Fields on our domain models can take one of three states. Normal - field can be written to, and read by clients, this is the state of unmarked fields. Read-only - field can be read by clients, but not modified. Private - field can not be read or updated by client. The dto.Mark enumeration lets us express these states on our domain models. dto.field() will accept the mark values as either the explicit enum, or its string representation, e.g., dto.field(dto.Mark.PRIVATE) and dto.field(\"private\") are equivalent. Example \u00b6 The following example demonstrates all field configurations available via the field() function. DTOField Configuration Example from __future__ import annotations from pydantic import Field , constr from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto def check_email ( email : str ) -> str : \"\"\"Validate an email.\"\"\" if \"@\" not in email : raise ValueError ( \"Invalid email!\" ) return email class Base ( DeclarativeBase ): \"\"\"Our ORM base class.\"\"\" class Thing ( Base ): \"\"\"Something in our domain.\"\"\" __tablename__ = \"things\" # demonstrates marking a field as \"read-only\" and overriding the generated pydantic `FieldInfo` # for the DTO field. id = mapped_column ( primary_key = True , info = dto . field ( \"read-only\" , pydantic_field = Field ( alias = \"identifier\" )) ) # demonstrates overriding the type assigned to the field in generated DTO always_upper : Mapped [ str ] = mapped_column ( info = dto . field ( pydantic_type = constr ( to_upper = True ))) # demonstrates setting a field as \"private\" private : Mapped [ str ] = mapped_column ( info = dto . field ( \"private\" )) # demonstrates setting a validator for the field email : Mapped [ str ] = mapped_column ( info = dto . field ( validators = [ check_email ])) SQLAlchemy info dictionary \u00b6 SQLAlchemy Column and relationship accept an info parameter, which allows us to store data alongside the columns and relationships of our model definitions. This is what we use to configure our DTOs at the model level. Info dict namespace key \u00b6 The key that is used to namespace our DTO configuration in the info dict is configurable via environment. By default, this is \"dto\" , however it can be changed to anything you like by setting the API_DTO_INFO_KEY environment variable. Configuring DTO Objects \u00b6 dto.DTOConfig \u00b6 This is the object that controls the generated DTO, and should be passed as the first argument to Annotated when declaring the DTO. For example, to create a \"read\" purposed DTO that excludes the \"id\" field: ReadDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.READ, exclude={\"id\"})]] The dto.config() function allows for more compact expression of DTO configuration. dto.config() \u00b6 Factory function for creating DTOConfig instances, and handles coercing the literal strings \"read\" and \"write\" to their dto.Purpose enum counterpart. For example to create a write purposed DTO using the dto.config() function: WriteDTO = dto.FromMapped[Annotated[Author, dto.config(\"write\")]] Which is equivalent to: WriteDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.WRITE)]] Annotated positional arguments \u00b6 The first argument to Annotated must always be the SQLAlchemy ORM type. We inspect a single additional positional argument after that, which can either be the string name of a dto.Purpose enum, or a dto.DTOConfig object. For example, these three definitions are equivalent: WriteDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.WRITE)]] WriteDTO = dto.FromMapped[Annotated[Author, dto.config(\"write\")]] WriteDTO = dto.FromMapped[Annotated[Author, \"write\"]] dto.Purpose \u00b6 dto.Purpose has two values, dto.Purpose.READ and dto.Purpose.WRITE . These are used to tell the factory if the purpose of the DTO is to parse data submitted by the client for updating or \"writing\" to a resource, or if it is to serialize data to be transmitted back to, or \"read\" by the client.","title":"DTOs"},{"location":"dto/#dtos","text":"","title":"DTOs"},{"location":"dto/#what-are-dtos","text":"DTO stands for \"Data Transfer Object\". They are the filter through which data is accepted into, and output from the application.","title":"What are DTOs?"},{"location":"dto/#why-dtos","text":"Data that is modifiable by clients, and that should be read by clients is often only a subset of the attributes that make up a domain object. For example, lets say we have an internal representation of an Author that looks like this: { \"id\" : \"97108ac1-ffcb-411d-8b1e-d9183399f63b\" , \"name\" : \"Agatha Christie\" , \"dob\" : \"1890-9-15\" , \"created\" : \"2022-11-27T01:58:00\" , \"updated\" : \"2022-11-27T01:59:00\" } Of those attributes, values for \"id\", \"created\" and \"updated\" are internally generated, and should not be available to be modified by clients of our application. This is where a DTO comes in. We create a type to validate user input that will only allow values for \"name\" and \"dob\" from clients, for example: { \"name\" : \"Agatha Christie\" , \"dob\" : \"1890-9-15\" }","title":"Why DTOs?"},{"location":"dto/#dtofrommapped","text":"Generate pydantic models from SQLAlchemy ORM models. Mark fields as \"read-only\" or \"private\" to control inclusion of fields on DTO models. Automatically infer defaults, and default factories from the SQLAlchemy column definitions. The dto.FromMapped type allows us to use our domain models, which are defined as SQLAlchemy ORM types, to generate DTOs. Here's a quick example. Simple Example from __future__ import annotations from datetime import date , datetime from typing import Annotated from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto class Base ( DeclarativeBase ): \"\"\"ORM base class. All SQLAlchemy ORM models must inherit from DeclarativeBase. We also define some common columns that we want to be present on every model in our domain. \"\"\" id : Mapped [ int ] = mapped_column ( primary_key = True ) created : Mapped [ datetime ] updated : Mapped [ datetime ] class Author ( Base ): \"\"\"A domain model. In addition to the columns defined on `Base` we have \"name\" and \"dob\". \"\"\" __tablename__ = \"authors\" name : Mapped [ str ] dob : Mapped [ date ] # This creates a DTO, which is simply a Pydantic model that inherits # from our special `FromMapped` subclass. We call it \"WriteDTO\" as it # is the model that we'll use to parse client data as they try to # \"write\" to (that is, create or update) authors in our domain. WriteDTO = dto . FromMapped [ Annotated [ Author , \"write\" ]] # we can inspect the fields that are available on the DTO print ( WriteDTO . __fields__ ) # { # \"id\": ModelField(name=\"id\", type=int, required=True), # \"created\": ModelField(name=\"created\", type=datetime, required=True), # \"updated\": ModelField(name=\"updated\", type=datetime, required=True), # \"name\": ModelField(name=\"name\", type=str, required=True), # \"dob\": ModelField(name=\"dob\", type=date, required=True), # } Read the comments in the example for a description of everything that is going on, however notice that the fields on our DTO type include \"id\", \"created\", and \"updated\" - fields that should not be modifiable by clients. Let's have another go: Simple Example with Read Only Fields from __future__ import annotations from datetime import date , datetime from typing import Annotated from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto class Base ( DeclarativeBase ): \"\"\"ORM base class. Using the dto.field() function, we've annotated that these columns are read-only. \"\"\" id : Mapped [ int ] = mapped_column ( primary_key = True , info = dto . field ( \"read-only\" )) created : Mapped [ datetime ] = mapped_column ( info = dto . field ( \"read-only\" )) updated : Mapped [ datetime ] = mapped_column ( info = dto . field ( \"read-only\" )) class Author ( Base ): \"\"\"Domain object.\"\"\" __tablename__ = \"authors\" name : Mapped [ str ] dob : Mapped [ date ] WriteDTO = dto . FromMapped [ Annotated [ Author , \"write\" ]] # now when we inspect our fields, we can see that our \"write\" purposed # DTO does not include any of the fields that we marked as \"read-only\" # fields. print ( WriteDTO . __fields__ ) # { # \"name\": ModelField(name=\"name\", type=str, required=True), # \"dob\": ModelField(name=\"dob\", type=date, required=True), # } That's better! Now, we'll only parse \"name\" and \"dob\" fields out of client input.","title":"dto.FromMapped"},{"location":"dto/#configuring-generated-dtos","text":"Th two main factors that influence how a DTO is generated for a given domain model are: The modifiability and privacy of the individual attributes of the domain model. The purpose of the DTO, is it to be used to parse and validate inbound client data, or to serialize outbound data.","title":"Configuring generated DTOs"},{"location":"dto/#configuring-dto-fields","text":"","title":"Configuring DTO Fields"},{"location":"dto/#dtodtofield","text":"This is the object that we use to configure DTO fields. To use the dto.DTOField object assign a dict to the mapped_column() or relationship info parameter, with the \"dto\" key and an instance of dto.DTOField as value, for example col: Mapped[str] = mapped_column(info={\"dto\": dto.DTOField(...)}) . The dto.DTOField object supports marking fields as \"read-only\" or \"private\" , setting an explicit pydantic FieldInfo and type, and setting validators for the field. The easiest way to configure a DTO field is through the dto.field() function.","title":"dto.DTOField"},{"location":"dto/#dtofield","text":"The dto.field() function creates an info dict for us, setting values on an dto.DTOField instance as appropriate. For example, the following are identical: col: Mapped[str] = mapped_column(info={\"dto\": dto.DTOField(mark=dto.Mark.PRIVATE)}) col: Mapped[str] = mapped_column(info=dto.field(\"private\")) field() supports the same arguments as DTOField , however it will also coerce string values for mark to the appropriate enum.","title":"dto.field()"},{"location":"dto/#dtomark","text":"Fields on our domain models can take one of three states. Normal - field can be written to, and read by clients, this is the state of unmarked fields. Read-only - field can be read by clients, but not modified. Private - field can not be read or updated by client. The dto.Mark enumeration lets us express these states on our domain models. dto.field() will accept the mark values as either the explicit enum, or its string representation, e.g., dto.field(dto.Mark.PRIVATE) and dto.field(\"private\") are equivalent.","title":"dto.Mark"},{"location":"dto/#example","text":"The following example demonstrates all field configurations available via the field() function. DTOField Configuration Example from __future__ import annotations from pydantic import Field , constr from sqlalchemy.orm import DeclarativeBase , Mapped , mapped_column from starlite_saqlalchemy import dto def check_email ( email : str ) -> str : \"\"\"Validate an email.\"\"\" if \"@\" not in email : raise ValueError ( \"Invalid email!\" ) return email class Base ( DeclarativeBase ): \"\"\"Our ORM base class.\"\"\" class Thing ( Base ): \"\"\"Something in our domain.\"\"\" __tablename__ = \"things\" # demonstrates marking a field as \"read-only\" and overriding the generated pydantic `FieldInfo` # for the DTO field. id = mapped_column ( primary_key = True , info = dto . field ( \"read-only\" , pydantic_field = Field ( alias = \"identifier\" )) ) # demonstrates overriding the type assigned to the field in generated DTO always_upper : Mapped [ str ] = mapped_column ( info = dto . field ( pydantic_type = constr ( to_upper = True ))) # demonstrates setting a field as \"private\" private : Mapped [ str ] = mapped_column ( info = dto . field ( \"private\" )) # demonstrates setting a validator for the field email : Mapped [ str ] = mapped_column ( info = dto . field ( validators = [ check_email ]))","title":"Example"},{"location":"dto/#sqlalchemy-info-dictionary","text":"SQLAlchemy Column and relationship accept an info parameter, which allows us to store data alongside the columns and relationships of our model definitions. This is what we use to configure our DTOs at the model level.","title":"SQLAlchemy info dictionary"},{"location":"dto/#info-dict-namespace-key","text":"The key that is used to namespace our DTO configuration in the info dict is configurable via environment. By default, this is \"dto\" , however it can be changed to anything you like by setting the API_DTO_INFO_KEY environment variable.","title":"Info dict namespace key"},{"location":"dto/#configuring-dto-objects","text":"","title":"Configuring DTO Objects"},{"location":"dto/#dtodtoconfig","text":"This is the object that controls the generated DTO, and should be passed as the first argument to Annotated when declaring the DTO. For example, to create a \"read\" purposed DTO that excludes the \"id\" field: ReadDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.READ, exclude={\"id\"})]] The dto.config() function allows for more compact expression of DTO configuration.","title":"dto.DTOConfig"},{"location":"dto/#dtoconfig","text":"Factory function for creating DTOConfig instances, and handles coercing the literal strings \"read\" and \"write\" to their dto.Purpose enum counterpart. For example to create a write purposed DTO using the dto.config() function: WriteDTO = dto.FromMapped[Annotated[Author, dto.config(\"write\")]] Which is equivalent to: WriteDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.WRITE)]]","title":"dto.config()"},{"location":"dto/#annotated-positional-arguments","text":"The first argument to Annotated must always be the SQLAlchemy ORM type. We inspect a single additional positional argument after that, which can either be the string name of a dto.Purpose enum, or a dto.DTOConfig object. For example, these three definitions are equivalent: WriteDTO = dto.FromMapped[Annotated[Author, dto.DTOConfig(purpose=dto.Purpose.WRITE)]] WriteDTO = dto.FromMapped[Annotated[Author, dto.config(\"write\")]] WriteDTO = dto.FromMapped[Annotated[Author, \"write\"]]","title":"Annotated positional arguments"},{"location":"dto/#dtopurpose","text":"dto.Purpose has two values, dto.Purpose.READ and dto.Purpose.WRITE . These are used to tell the factory if the purpose of the DTO is to parse data submitted by the client for updating or \"writing\" to a resource, or if it is to serialize data to be transmitted back to, or \"read\" by the client.","title":"dto.Purpose"},{"location":"logging/","text":"Logging \u00b6 starlite-saqlalchemy has structured logging baked-in, built around facilitating the Canonical Log Lines pattern (which is basically, a single log line per request or async worker invocation). The pattern is built upon the excellent structlog library, and is configured to be as efficient as possible while not blocking the event loop (it runs the logging in a processor thread). Adding data to the log \u00b6 To bind a key/value pair to the log object anywhere within the application, use structlog.contextvars.bind_contextvars . from structlog.contextvars import bind_contextvars def do_something () -> None : ... bind_contextvars ( i_did = \"something\" ) Whether you call that in the context of handling an HTTP request, or during an async worker invocation, it doesn't matter, that key/value pair will be included in the log representing that invocation. Controller Logging \u00b6 Middleware \u00b6 The configuration adds a very light-weight middleware that simply clears the context-local storage for each request. Before Send Hook Handler \u00b6 We add a handler to Starlite's before_send hook. That allows us to do two things: We inspect the outbound messages looking for a Response Start event. When that is located, we stash the message into the connection scope state, for later use. We also use this event to determine the severity of the eventual log message. If the status code is in the 500s we log at ERROR, otherwise INFO. We inspect the outbound messages looking for a Response Body event. This event has a property called more_body , for streaming responses this flag indicates whether there is another Response Body message to come. If more_body is True we do nothing, but once we receive the final Response Body message of the request we use it to construct the response log, and finally emit the log message at the predetermined severity level. Example \u00b6 Here's an example of a log emitted with the default configuration (I've applied the formatting for the purposes of this documentation, the logger emits un-formatted json): { \"event\" : \"HTTP\" , \"level\" : \"info\" , \"request\" : { \"body\" : { \"dob\" : \"1890-9-15\" , \"name\" : \"TEST UPDATE\" }, \"content_type\" : [ \"application/json\" , {} ], \"cookies\" : {}, \"headers\" : { \"accept\" : \"*/*\" , \"accept-encoding\" : \"gzip, deflate\" , \"connection\" : \"keep-alive\" , \"content-length\" : \"43\" , \"content-type\" : \"application/json\" , \"host\" : \"testserver\" , \"user-agent\" : \"python-httpx/0.23.0\" }, \"method\" : \"PUT\" , \"path\" : \"/authors/97108ac1-ffcb-411d-8b1e-d9183399f63b\" , \"path_params\" : { \"author_id\" : \"97108ac1-ffcb-411d-8b1e-d9183399f63b\" }, \"query\" : {} }, \"response\" : { \"body\" : \"b'{\\\"id\\\":\\\"97108ac1-ffcb-411d-8b1e-d9183399f63b\\\",\\\"created\\\":\\\"0001-01-01T00:00:00\\\",\\\"updated\\\":\\\"2022-11-04T14:15:16\\\",\\\"name\\\":\\\"TEST UPDATE\\\",\\\"dob\\\":\\\"1890-09-15\\\"}'\" , \"cookies\" : {}, \"headers\" : { \"content-length\" : \"149\" , \"content-type\" : \"application/json\" }, \"status_code\" : 200 }, \"timestamp\" : \"2022-11-04T04:15:16.766464Z\" } Controlling Log Content \u00b6 As you can see, we are including a lot of data in our logs that may include sensitive values, such as PII and secrets. Thankfully, we have mechanisms to ensure that this type of data is excluded from our logs! Our LogSettings object provides a host of options that allow you to customize log output. This exposes the following environment variables: LOG_EXCLUDE_PATHS \u00b6 This is a regular expression that is matched against the path of the request before logging. If the path matches the regex, the route is not logged. For example, the value ^/a will exclude any path that begins with /a , such as /apath and /a/path . Explicit paths can be excluded by using the \"start\" ( ^ ) and \"end\" ( $ ) symbols, for example ^/never-log$ will exclude the path /never-log but will not exclude /never-log/just/joking . Multiple regexes can be concatenated with the \"or\" symbol ( | ). LOG_OBFUSCATE_COOKIES & LOG_OBFUSCATE_HEADERS \u00b6 These two environment variables allow you to specify header and cookie names, whose value will be obfuscated in the logs. This leverages functionality that is provided via Starlite's Extraction Utils . Simply provide the exact name of the cookies and headers that should be obfuscated. As environment variables are parsed by pydantic, collections such as these should be JSON strings (per their documentation ) . For example: LOG_OBFUSCATE_HEADERS='[\"Authorization\", \"X-API-KEY\"]'` LOG_REQUEST_FIELDS & LOG_RESPONSE_FIELDS \u00b6 These specify the fields from the ASGI Connection Scope and response messages that are included in logs. As environment variables are parsed by pydantic, collections such as these should be JSON strings (per their documentation ) . For example: REQUEST_FIELDS='[\"path\", \"method\", \"content_type\", \"headers\", \"cookies\", \"query\", \"path_params\", \"body\"]' The above is the default configuration for this setting, so if you are happy with that you don't need to do anything. However, lets say you never want to log the request body, you could define this in your environment and simply exclude \"body\" from that collection: REQUEST_FIELDS='[\"path\", \"method\", \"content_type\", \"headers\", \"cookies\", \"query\", \"path_params\"]' Other Log Config \u00b6 There are some other logging configurations that you can control via environment LOG_HTTP_EVENT & LOG_WORKER_EVENT \u00b6 These define the value of the \"event\" key in the emitted log object. By default, LOG_HTTP_EVENT is \"HTTP\" and LOG_WORKER_EVENT is \"Worker\" . E.g., a log emitted by the HTTP handlers will be {\"event\": \"HTTP\", ...} and one emitted by the worker will be {\"event\": \"Worker\", ...} . LOG_LEVEL \u00b6 Set this according to the standard library logging levels. Any message emitted at a level that is below this one will be silently (and efficiently, thanks to structlog ) dropped. For example, setting LOG_LEVEL=WARNING in your environment would mean that no INFO level logs would ever be emitted by the application. More Goodies \u00b6 Automatic dropping of health check logs \u00b6 Successful health check logs are dropped early in the processor chain. This prevents your logs getting clogged up with \"white noise\" and all the associated data storage and ingestion costs that go along with it. Of course, if you health checks fail, there's nothing worse than those logs getting dropped too, so any response from the health check handler not within the success status range is logged. Standard library logging config \u00b6 We configure the standard library logger with a queue listener and handler and route any logs from our dependencies through that, so they won't block the event loop. Environment specific processor chain \u00b6 We inspect stdout destination to determine if it is writing to a terminal and modify the processor chain so that you get pretty log output when developing locally! Worker Logging \u00b6 Worker.before_process \u00b6 If logging configuration is enabled, we use this SAQ Worker hook to clear the structlog contextvars for the job. Worker.after_process \u00b6 If logging configuration is enabled, we use this SAQ Worker hook to extract the configured Job attributes and inject them into the log, and emit the log event. The attributes that are logged for each Job can be configured in LogSettings . If the Job.error attribute is truthy, we log at ERROR severity, otherwise log at INFO . SAQ Logs \u00b6 SAQ emits logs via standard library logging, we restrict these to level of WARNING or higher, and handle them using the asyncio-friendly queue_handler that is provided to us by Starlite. That means, you might see the following logs emitted from the SAQ logger: worker.py \u00b6 class Worker \u00b6 upkeep(): l181 - EXCEPTION - on failed upkeep task process(): l253 - EXCEPTION - on job error process(): l270 - EXCEPTION - on after process hook failure def async_check_health() \u00b6 l343 - WARNING - on health check failure","title":"Logging"},{"location":"logging/#logging","text":"starlite-saqlalchemy has structured logging baked-in, built around facilitating the Canonical Log Lines pattern (which is basically, a single log line per request or async worker invocation). The pattern is built upon the excellent structlog library, and is configured to be as efficient as possible while not blocking the event loop (it runs the logging in a processor thread).","title":"Logging"},{"location":"logging/#adding-data-to-the-log","text":"To bind a key/value pair to the log object anywhere within the application, use structlog.contextvars.bind_contextvars . from structlog.contextvars import bind_contextvars def do_something () -> None : ... bind_contextvars ( i_did = \"something\" ) Whether you call that in the context of handling an HTTP request, or during an async worker invocation, it doesn't matter, that key/value pair will be included in the log representing that invocation.","title":"Adding data to the log"},{"location":"logging/#controller-logging","text":"","title":"Controller Logging"},{"location":"logging/#middleware","text":"The configuration adds a very light-weight middleware that simply clears the context-local storage for each request.","title":"Middleware"},{"location":"logging/#before-send-hook-handler","text":"We add a handler to Starlite's before_send hook. That allows us to do two things: We inspect the outbound messages looking for a Response Start event. When that is located, we stash the message into the connection scope state, for later use. We also use this event to determine the severity of the eventual log message. If the status code is in the 500s we log at ERROR, otherwise INFO. We inspect the outbound messages looking for a Response Body event. This event has a property called more_body , for streaming responses this flag indicates whether there is another Response Body message to come. If more_body is True we do nothing, but once we receive the final Response Body message of the request we use it to construct the response log, and finally emit the log message at the predetermined severity level.","title":"Before Send Hook Handler"},{"location":"logging/#example","text":"Here's an example of a log emitted with the default configuration (I've applied the formatting for the purposes of this documentation, the logger emits un-formatted json): { \"event\" : \"HTTP\" , \"level\" : \"info\" , \"request\" : { \"body\" : { \"dob\" : \"1890-9-15\" , \"name\" : \"TEST UPDATE\" }, \"content_type\" : [ \"application/json\" , {} ], \"cookies\" : {}, \"headers\" : { \"accept\" : \"*/*\" , \"accept-encoding\" : \"gzip, deflate\" , \"connection\" : \"keep-alive\" , \"content-length\" : \"43\" , \"content-type\" : \"application/json\" , \"host\" : \"testserver\" , \"user-agent\" : \"python-httpx/0.23.0\" }, \"method\" : \"PUT\" , \"path\" : \"/authors/97108ac1-ffcb-411d-8b1e-d9183399f63b\" , \"path_params\" : { \"author_id\" : \"97108ac1-ffcb-411d-8b1e-d9183399f63b\" }, \"query\" : {} }, \"response\" : { \"body\" : \"b'{\\\"id\\\":\\\"97108ac1-ffcb-411d-8b1e-d9183399f63b\\\",\\\"created\\\":\\\"0001-01-01T00:00:00\\\",\\\"updated\\\":\\\"2022-11-04T14:15:16\\\",\\\"name\\\":\\\"TEST UPDATE\\\",\\\"dob\\\":\\\"1890-09-15\\\"}'\" , \"cookies\" : {}, \"headers\" : { \"content-length\" : \"149\" , \"content-type\" : \"application/json\" }, \"status_code\" : 200 }, \"timestamp\" : \"2022-11-04T04:15:16.766464Z\" }","title":"Example"},{"location":"logging/#controlling-log-content","text":"As you can see, we are including a lot of data in our logs that may include sensitive values, such as PII and secrets. Thankfully, we have mechanisms to ensure that this type of data is excluded from our logs! Our LogSettings object provides a host of options that allow you to customize log output. This exposes the following environment variables:","title":"Controlling Log Content"},{"location":"logging/#log_exclude_paths","text":"This is a regular expression that is matched against the path of the request before logging. If the path matches the regex, the route is not logged. For example, the value ^/a will exclude any path that begins with /a , such as /apath and /a/path . Explicit paths can be excluded by using the \"start\" ( ^ ) and \"end\" ( $ ) symbols, for example ^/never-log$ will exclude the path /never-log but will not exclude /never-log/just/joking . Multiple regexes can be concatenated with the \"or\" symbol ( | ).","title":"LOG_EXCLUDE_PATHS"},{"location":"logging/#log_obfuscate_cookies-log_obfuscate_headers","text":"These two environment variables allow you to specify header and cookie names, whose value will be obfuscated in the logs. This leverages functionality that is provided via Starlite's Extraction Utils . Simply provide the exact name of the cookies and headers that should be obfuscated. As environment variables are parsed by pydantic, collections such as these should be JSON strings (per their documentation ) . For example: LOG_OBFUSCATE_HEADERS='[\"Authorization\", \"X-API-KEY\"]'`","title":"LOG_OBFUSCATE_COOKIES &amp; LOG_OBFUSCATE_HEADERS"},{"location":"logging/#log_request_fields-log_response_fields","text":"These specify the fields from the ASGI Connection Scope and response messages that are included in logs. As environment variables are parsed by pydantic, collections such as these should be JSON strings (per their documentation ) . For example: REQUEST_FIELDS='[\"path\", \"method\", \"content_type\", \"headers\", \"cookies\", \"query\", \"path_params\", \"body\"]' The above is the default configuration for this setting, so if you are happy with that you don't need to do anything. However, lets say you never want to log the request body, you could define this in your environment and simply exclude \"body\" from that collection: REQUEST_FIELDS='[\"path\", \"method\", \"content_type\", \"headers\", \"cookies\", \"query\", \"path_params\"]'","title":"LOG_REQUEST_FIELDS &amp; LOG_RESPONSE_FIELDS"},{"location":"logging/#other-log-config","text":"There are some other logging configurations that you can control via environment","title":"Other Log Config"},{"location":"logging/#log_http_event-log_worker_event","text":"These define the value of the \"event\" key in the emitted log object. By default, LOG_HTTP_EVENT is \"HTTP\" and LOG_WORKER_EVENT is \"Worker\" . E.g., a log emitted by the HTTP handlers will be {\"event\": \"HTTP\", ...} and one emitted by the worker will be {\"event\": \"Worker\", ...} .","title":"LOG_HTTP_EVENT &amp; LOG_WORKER_EVENT"},{"location":"logging/#log_level","text":"Set this according to the standard library logging levels. Any message emitted at a level that is below this one will be silently (and efficiently, thanks to structlog ) dropped. For example, setting LOG_LEVEL=WARNING in your environment would mean that no INFO level logs would ever be emitted by the application.","title":"LOG_LEVEL"},{"location":"logging/#more-goodies","text":"","title":"More Goodies"},{"location":"logging/#automatic-dropping-of-health-check-logs","text":"Successful health check logs are dropped early in the processor chain. This prevents your logs getting clogged up with \"white noise\" and all the associated data storage and ingestion costs that go along with it. Of course, if you health checks fail, there's nothing worse than those logs getting dropped too, so any response from the health check handler not within the success status range is logged.","title":"Automatic dropping of health check logs"},{"location":"logging/#standard-library-logging-config","text":"We configure the standard library logger with a queue listener and handler and route any logs from our dependencies through that, so they won't block the event loop.","title":"Standard library logging config"},{"location":"logging/#environment-specific-processor-chain","text":"We inspect stdout destination to determine if it is writing to a terminal and modify the processor chain so that you get pretty log output when developing locally!","title":"Environment specific processor chain"},{"location":"logging/#worker-logging","text":"","title":"Worker Logging"},{"location":"logging/#workerbefore_process","text":"If logging configuration is enabled, we use this SAQ Worker hook to clear the structlog contextvars for the job.","title":"Worker.before_process"},{"location":"logging/#workerafter_process","text":"If logging configuration is enabled, we use this SAQ Worker hook to extract the configured Job attributes and inject them into the log, and emit the log event. The attributes that are logged for each Job can be configured in LogSettings . If the Job.error attribute is truthy, we log at ERROR severity, otherwise log at INFO .","title":"Worker.after_process"},{"location":"logging/#saq-logs","text":"SAQ emits logs via standard library logging, we restrict these to level of WARNING or higher, and handle them using the asyncio-friendly queue_handler that is provided to us by Starlite. That means, you might see the following logs emitted from the SAQ logger:","title":"SAQ Logs"},{"location":"logging/#workerpy","text":"","title":"worker.py"},{"location":"logging/#class-worker","text":"upkeep(): l181 - EXCEPTION - on failed upkeep task process(): l253 - EXCEPTION - on job error process(): l270 - EXCEPTION - on after process hook failure","title":"class Worker"},{"location":"logging/#def-async_check_health","text":"l343 - WARNING - on health check failure","title":"def async_check_health()"},{"location":"reference/SUMMARY/","text":"pytest_starlite_saqlalchemy plugin starlite_saqlalchemy cache compression constants db orm dependencies dto from_mapped types utils endpoint_decorator exceptions health http init_plugin lifespan log controller utils worker openapi redis repository abc filters sqlalchemy types scripts sentry service settings sqlalchemy_plugin testing controller_test generic_mock_repository modify_settings type_encoders utils worker","title":"SUMMARY"},{"location":"reference/pytest_starlite_saqlalchemy/","text":"Pytest plugin to support testing starlite-saqlalchemy applications.","title":"pytest_starlite_saqlalchemy"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/","text":"Pytest plugin to support testing starlite-saqlalchemy applications. fx_app \u00b6 fx_app ( pytestconfig , monkeypatch ) Returns: Type Description Starlite An application instance, configured via plugin. fx_cap_logger \u00b6 fx_cap_logger ( monkeypatch ) Used to monkeypatch the app logger, so we can inspect output. fx_client \u00b6 fx_client ( app ) Test client fixture for making calls on the global app instance. fx_is_unit_test \u00b6 fx_is_unit_test ( request ) Uses the ini option unit_test_pattern to determine if the test is part of unit or integration tests. pytest_addoption \u00b6 pytest_addoption ( parser ) Adds Pytest ini config variables for the plugin.","title":"plugin"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/#pytest_starlite_saqlalchemy.plugin.fx_app","text":"fx_app ( pytestconfig , monkeypatch ) Returns: Type Description Starlite An application instance, configured via plugin.","title":"fx_app()"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/#pytest_starlite_saqlalchemy.plugin.fx_cap_logger","text":"fx_cap_logger ( monkeypatch ) Used to monkeypatch the app logger, so we can inspect output.","title":"fx_cap_logger()"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/#pytest_starlite_saqlalchemy.plugin.fx_client","text":"fx_client ( app ) Test client fixture for making calls on the global app instance.","title":"fx_client()"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/#pytest_starlite_saqlalchemy.plugin.fx_is_unit_test","text":"fx_is_unit_test ( request ) Uses the ini option unit_test_pattern to determine if the test is part of unit or integration tests.","title":"fx_is_unit_test()"},{"location":"reference/pytest_starlite_saqlalchemy/plugin/#pytest_starlite_saqlalchemy.plugin.pytest_addoption","text":"pytest_addoption ( parser ) Adds Pytest ini config variables for the plugin.","title":"pytest_addoption()"},{"location":"reference/starlite_saqlalchemy/","text":"starlite-saqlalchemy \u00b6 An implementation of a Starlite application configuration plugin. Example: from starlite import Starlite , get from starlite_saqlalchemy import ConfigureApp @get ( \"/example\" ) def example_handler () -> dict : return { \"hello\" : \"world\" } app = Starlite ( route_handlers = [ example_handler ], on_app_init = [ ConfigureApp ()]) ConfigureApp \u00b6 ConfigureApp ( config = PluginConfig ()) Starlite application configuration. __call__ \u00b6 __call__ ( app_config ) Entrypoint to the app config plugin. Receives the AppConfig object and modifies it. Parameters: Name Type Description Default app_config AppConfig Passed to the plugin from the Starlite instance on instantiation. required Returns: Type Description AppConfig The modified AppConfig object. configure_after_exception \u00b6 configure_after_exception ( app_config ) Add the logging after exception hook handler. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_cache \u00b6 configure_cache ( app_config ) Configure the application cache. We only overwrite if DEFAULT_CACHE_CONFIG is the standing configuration object. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_collection_dependencies \u00b6 configure_collection_dependencies ( app_config ) Add the required Provide instances to the app dependency mapping. If a dependency has already been provided with the same key we do not overwrite it. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_compression \u00b6 configure_compression ( app_config ) Configure application compression. No-op if AppConfig.compression_config has already been set. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_debug \u00b6 configure_debug ( app_config ) Set the Starlite debug parameter. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_exception_handlers \u00b6 configure_exception_handlers ( app_config ) Add the handlers that translate service and repository exceptions into HTTP exceptions. Does not overwrite handlers that may already exist for the exception types. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_health_check \u00b6 configure_health_check ( app_config ) Add health check controller. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_logging \u00b6 configure_logging ( app_config ) Configure application logging. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_openapi \u00b6 configure_openapi ( app_config ) Configure the OpenAPI docs. We only overwrite if DEFAULT_OPENAPI_CONFIG is the standing configuration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_sentry \u00b6 configure_sentry ( app_config ) Add handler to configure Sentry integration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_sqlalchemy_plugin \u00b6 configure_sqlalchemy_plugin ( app_config ) Configure SQLAlchemy for the application. Adds a configured SQLAlchemyPlugin to AppConfig.plugins . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_type_encoders \u00b6 configure_type_encoders ( app_config ) Set mapping of type encoders on the application config. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_worker \u00b6 configure_worker ( app_config ) Configure the SAQ async worker. No-op if there are no worker functions set on PluginConfig . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required PluginConfig \u00b6 Bases: BaseModel Configure behavior of the ConfigureApp object. Each feature that the plugin enables can be toggled with the do_<behavior> switch, e.g., PluginConfig(do_after_exception=False) will tell ConfigureApp not to add the after exception logging hook handler to the application. do_after_exception class-attribute \u00b6 do_after_exception : bool = True Configure after exception handler. Add the hook handler to AppConfig.after_exception . do_cache class-attribute \u00b6 do_cache : bool = True Configure redis cache backend. Add configuration for the redis-backed cache to AppConfig.cache_config . do_collection_dependencies class-attribute \u00b6 do_collection_dependencies = True Add collection route dependencies. Add the Provide 's for collection route dependencies to AppConfig.dependencies . do_compression class-attribute \u00b6 do_compression : bool = True Confiture compression backend. Add configuration for gzip compression to AppConfig.compression_config . do_exception_handlers class-attribute \u00b6 do_exception_handlers : bool = True Configure exception handlers. Add the repository/service exception http translation handlers to AppConfig.exception_handlers . do_health_check class-attribute \u00b6 do_health_check : bool = True Configure a health check. Add the health check controller to AppConfig.route_handlers . do_logging class-attribute \u00b6 do_logging : bool = True Configure logging. Set the logging configuration object to AppConfig.logging_config . do_openapi class-attribute \u00b6 do_openapi : bool = True Configure OpenAPI. Set the OpenAPI config object to AppConfig.openapi_config . do_sentry class-attribute \u00b6 do_sentry : bool | None = None Configure sentry. Configure the application to initialize Sentry on startup. Adds a handler to AppConfig.on_startup . do_set_debug class-attribute \u00b6 do_set_debug : bool = True Configure Starlite debug mode. Allow the plugin to set the starlite debug parameter. Parameter set to value of AppConfig.debug . do_sqlalchemy_plugin class-attribute \u00b6 do_sqlalchemy_plugin : bool = True Configure SQLAlchemy plugin. Set the SQLAlchemy plugin on the application. Adds the plugin to AppConfig.plugins . do_type_encoders class-attribute \u00b6 do_type_encoders : bool = True Configure custom type encoders on the app. do_worker class-attribute \u00b6 do_worker : bool = True Configure the async worker on the application. This action instantiates a worker instance and sets handlers for AppConfig.on_startup and AppConfig.on_shutdown that manage the lifecycle of the SAQ worker. log_processors class-attribute \u00b6 log_processors : Sequence [ Processor ] = log . default_processors Chain of structlog log processors. type_encoders class-attribute \u00b6 type_encoders : TypeEncodersMap = type_encoders_map Map of type to serializer callable. worker_functions class-attribute \u00b6 worker_functions : list [ Callable [ ... , Any ] | tuple [ str , Callable [ ... , Any ]]] = [ ( make_service_callback . __qualname__ , make_service_callback ) ] Queue worker functions.","title":"starlite_saqlalchemy"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy--starlite-saqlalchemy","text":"An implementation of a Starlite application configuration plugin. Example: from starlite import Starlite , get from starlite_saqlalchemy import ConfigureApp @get ( \"/example\" ) def example_handler () -> dict : return { \"hello\" : \"world\" } app = Starlite ( route_handlers = [ example_handler ], on_app_init = [ ConfigureApp ()])","title":"starlite-saqlalchemy"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.ConfigureApp","text":"ConfigureApp ( config = PluginConfig ()) Starlite application configuration.","title":"ConfigureApp"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.__call__","text":"__call__ ( app_config ) Entrypoint to the app config plugin. Receives the AppConfig object and modifies it. Parameters: Name Type Description Default app_config AppConfig Passed to the plugin from the Starlite instance on instantiation. required Returns: Type Description AppConfig The modified AppConfig object.","title":"__call__()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_after_exception","text":"configure_after_exception ( app_config ) Add the logging after exception hook handler. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_after_exception()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_cache","text":"configure_cache ( app_config ) Configure the application cache. We only overwrite if DEFAULT_CACHE_CONFIG is the standing configuration object. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_cache()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_collection_dependencies","text":"configure_collection_dependencies ( app_config ) Add the required Provide instances to the app dependency mapping. If a dependency has already been provided with the same key we do not overwrite it. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_collection_dependencies()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_compression","text":"configure_compression ( app_config ) Configure application compression. No-op if AppConfig.compression_config has already been set. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_compression()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_debug","text":"configure_debug ( app_config ) Set the Starlite debug parameter. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_debug()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_exception_handlers","text":"configure_exception_handlers ( app_config ) Add the handlers that translate service and repository exceptions into HTTP exceptions. Does not overwrite handlers that may already exist for the exception types. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_exception_handlers()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_health_check","text":"configure_health_check ( app_config ) Add health check controller. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_health_check()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_logging","text":"configure_logging ( app_config ) Configure application logging. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_logging()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_openapi","text":"configure_openapi ( app_config ) Configure the OpenAPI docs. We only overwrite if DEFAULT_OPENAPI_CONFIG is the standing configuration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_openapi()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_sentry","text":"configure_sentry ( app_config ) Add handler to configure Sentry integration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_sentry()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_sqlalchemy_plugin","text":"configure_sqlalchemy_plugin ( app_config ) Configure SQLAlchemy for the application. Adds a configured SQLAlchemyPlugin to AppConfig.plugins . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_sqlalchemy_plugin()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_type_encoders","text":"configure_type_encoders ( app_config ) Set mapping of type encoders on the application config. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_type_encoders()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_worker","text":"configure_worker ( app_config ) Configure the SAQ async worker. No-op if there are no worker functions set on PluginConfig . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_worker()"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.PluginConfig","text":"Bases: BaseModel Configure behavior of the ConfigureApp object. Each feature that the plugin enables can be toggled with the do_<behavior> switch, e.g., PluginConfig(do_after_exception=False) will tell ConfigureApp not to add the after exception logging hook handler to the application.","title":"PluginConfig"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_after_exception","text":"do_after_exception : bool = True Configure after exception handler. Add the hook handler to AppConfig.after_exception .","title":"do_after_exception"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_cache","text":"do_cache : bool = True Configure redis cache backend. Add configuration for the redis-backed cache to AppConfig.cache_config .","title":"do_cache"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_collection_dependencies","text":"do_collection_dependencies = True Add collection route dependencies. Add the Provide 's for collection route dependencies to AppConfig.dependencies .","title":"do_collection_dependencies"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_compression","text":"do_compression : bool = True Confiture compression backend. Add configuration for gzip compression to AppConfig.compression_config .","title":"do_compression"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_exception_handlers","text":"do_exception_handlers : bool = True Configure exception handlers. Add the repository/service exception http translation handlers to AppConfig.exception_handlers .","title":"do_exception_handlers"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_health_check","text":"do_health_check : bool = True Configure a health check. Add the health check controller to AppConfig.route_handlers .","title":"do_health_check"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_logging","text":"do_logging : bool = True Configure logging. Set the logging configuration object to AppConfig.logging_config .","title":"do_logging"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_openapi","text":"do_openapi : bool = True Configure OpenAPI. Set the OpenAPI config object to AppConfig.openapi_config .","title":"do_openapi"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_sentry","text":"do_sentry : bool | None = None Configure sentry. Configure the application to initialize Sentry on startup. Adds a handler to AppConfig.on_startup .","title":"do_sentry"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_set_debug","text":"do_set_debug : bool = True Configure Starlite debug mode. Allow the plugin to set the starlite debug parameter. Parameter set to value of AppConfig.debug .","title":"do_set_debug"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_sqlalchemy_plugin","text":"do_sqlalchemy_plugin : bool = True Configure SQLAlchemy plugin. Set the SQLAlchemy plugin on the application. Adds the plugin to AppConfig.plugins .","title":"do_sqlalchemy_plugin"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_type_encoders","text":"do_type_encoders : bool = True Configure custom type encoders on the app.","title":"do_type_encoders"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.do_worker","text":"do_worker : bool = True Configure the async worker on the application. This action instantiates a worker instance and sets handlers for AppConfig.on_startup and AppConfig.on_shutdown that manage the lifecycle of the SAQ worker.","title":"do_worker"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.log_processors","text":"log_processors : Sequence [ Processor ] = log . default_processors Chain of structlog log processors.","title":"log_processors"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.type_encoders","text":"type_encoders : TypeEncodersMap = type_encoders_map Map of type to serializer callable.","title":"type_encoders"},{"location":"reference/starlite_saqlalchemy/#starlite_saqlalchemy.init_plugin.PluginConfig.worker_functions","text":"worker_functions : list [ Callable [ ... , Any ] | tuple [ str , Callable [ ... , Any ]]] = [ ( make_service_callback . __qualname__ , make_service_callback ) ] Queue worker functions.","title":"worker_functions"},{"location":"reference/starlite_saqlalchemy/cache/","text":"Application cache config. config module-attribute \u00b6 config = CacheConfig ( backend = redis . client , expiration = settings . api . CACHE_EXPIRATION , cache_key_builder = cache_key_builder , ) Cache configuration for application. cache_key_builder \u00b6 cache_key_builder ( request ) Parameters: Name Type Description Default request Request [ Any , Any ] Current request instance. required Returns: Type Description str App slug prefixed cache key.","title":"cache"},{"location":"reference/starlite_saqlalchemy/cache/#starlite_saqlalchemy.cache.config","text":"config = CacheConfig ( backend = redis . client , expiration = settings . api . CACHE_EXPIRATION , cache_key_builder = cache_key_builder , ) Cache configuration for application.","title":"config"},{"location":"reference/starlite_saqlalchemy/cache/#starlite_saqlalchemy.cache.cache_key_builder","text":"cache_key_builder ( request ) Parameters: Name Type Description Default request Request [ Any , Any ] Current request instance. required Returns: Type Description str App slug prefixed cache key.","title":"cache_key_builder()"},{"location":"reference/starlite_saqlalchemy/compression/","text":"Compression configuration for the application. config module-attribute \u00b6 config = CompressionConfig ( backend = 'gzip' ) Default compression config.","title":"compression"},{"location":"reference/starlite_saqlalchemy/compression/#starlite_saqlalchemy.compression.config","text":"config = CompressionConfig ( backend = 'gzip' ) Default compression config.","title":"config"},{"location":"reference/starlite_saqlalchemy/constants/","text":"Application constants. IS_LOCAL_ENVIRONMENT module-attribute \u00b6 IS_LOCAL_ENVIRONMENT = case_insensitive_string_compare ( app . ENVIRONMENT , app . LOCAL_ENVIRONMENT_NAME ) Flag indicating if application is running in local development mode. IS_TEST_ENVIRONMENT module-attribute \u00b6 IS_TEST_ENVIRONMENT = case_insensitive_string_compare ( app . ENVIRONMENT , app . TEST_ENVIRONMENT_NAME ) Flag indicating if the application is running in a test environment.","title":"constants"},{"location":"reference/starlite_saqlalchemy/constants/#starlite_saqlalchemy.constants.IS_LOCAL_ENVIRONMENT","text":"IS_LOCAL_ENVIRONMENT = case_insensitive_string_compare ( app . ENVIRONMENT , app . LOCAL_ENVIRONMENT_NAME ) Flag indicating if application is running in local development mode.","title":"IS_LOCAL_ENVIRONMENT"},{"location":"reference/starlite_saqlalchemy/constants/#starlite_saqlalchemy.constants.IS_TEST_ENVIRONMENT","text":"IS_TEST_ENVIRONMENT = case_insensitive_string_compare ( app . ENVIRONMENT , app . TEST_ENVIRONMENT_NAME ) Flag indicating if the application is running in a test environment.","title":"IS_TEST_ENVIRONMENT"},{"location":"reference/starlite_saqlalchemy/dependencies/","text":"Application dependency providers. create_collection_dependencies \u00b6 create_collection_dependencies () Build mapping of collection dependencies. Returns: Type Description dict [ str , Provide ] A dictionary of provides for pagination endpoints. provide_created_filter \u00b6 provide_created_filter ( before = Parameter ( query = \"created-before\" , default = None , required = False ), after = Parameter ( query = \"created-after\" , default = None , required = False ), ) Parameters: Name Type Description Default before DTorNone Filter for records created before this date/time. Parameter(query='created-before', default=None, required=False) after DTorNone Filter for records created after this date/time. Parameter(query='created-after', default=None, required=False) Returns: Type Description BeforeAfter Type consumed by Repository.filter_on_datetime_field() . provide_filter_dependencies \u00b6 provide_filter_dependencies ( created_filter = Dependency ( skip_validation = True ), updated_filter = Dependency ( skip_validation = True ), id_filter = Dependency ( skip_validation = True ), limit_offset = Dependency ( skip_validation = True ), ) Inject filtering dependencies. Add all filters to any route by including this function as a dependency, e.g: @get def get_collection_handler ( filters : Filters ) -> ... : ... The dependency is provided at the application layer, so only need to inject the dependency where it is required. Parameters: Name Type Description Default id_filter CollectionFilter [ UUID ] Filter for scoping query to limited set of identities. Dependency(skip_validation=True) created_filter BeforeAfter Filter for scoping query to instance creation date/time. Dependency(skip_validation=True) updated_filter BeforeAfter Filter for scoping query to instance update date/time. Dependency(skip_validation=True) limit_offset LimitOffset Filter for query pagination. Dependency(skip_validation=True) Returns: Type Description list [ FilterTypes ] List of filters parsed from connection. provide_id_filter \u00b6 provide_id_filter ( ids = Parameter ( query = 'ids' , default = None , required = False )) Parameters: Name Type Description Default ids list [ UUID ] | None Parsed out of query params. Parameter(query='ids', default=None, required=False) Returns: Type Description CollectionFilter [ UUID ] Type consumed by AbstractRepository.filter_in_collection() provide_limit_offset_pagination \u00b6 provide_limit_offset_pagination ( page = Parameter ( ge = 1 , default = 1 , required = False ), page_size = Parameter ( query = \"page-size\" , ge = 1 , default = settings . api . DEFAULT_PAGINATION_LIMIT , required = False ), ) Parameters: Name Type Description Default page int LIMIT to apply to select. Parameter(ge=1, default=1, required=False) page_size int OFFSET to apply to select. Parameter(query='page-size', ge=1, default=settings.api.DEFAULT_PAGINATION_LIMIT, required=False) Returns: Type Description LimitOffset Type consumed by Repository.apply_limit_offset_pagination() . provide_updated_filter \u00b6 provide_updated_filter ( before = Parameter ( query = \"updated-before\" , default = None , required = False ), after = Parameter ( query = \"updated-after\" , default = None , required = False ), ) Parameters: Name Type Description Default before DTorNone Filter for records updated before this date/time. Parameter(query='updated-before', default=None, required=False) after DTorNone Filter for records updated after this date/time. Parameter(query='updated-after', default=None, required=False) Returns: Type Description BeforeAfter Type consumed by Repository.filter_on_datetime_field() .","title":"dependencies"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.create_collection_dependencies","text":"create_collection_dependencies () Build mapping of collection dependencies. Returns: Type Description dict [ str , Provide ] A dictionary of provides for pagination endpoints.","title":"create_collection_dependencies()"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.provide_created_filter","text":"provide_created_filter ( before = Parameter ( query = \"created-before\" , default = None , required = False ), after = Parameter ( query = \"created-after\" , default = None , required = False ), ) Parameters: Name Type Description Default before DTorNone Filter for records created before this date/time. Parameter(query='created-before', default=None, required=False) after DTorNone Filter for records created after this date/time. Parameter(query='created-after', default=None, required=False) Returns: Type Description BeforeAfter Type consumed by Repository.filter_on_datetime_field() .","title":"provide_created_filter()"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.provide_filter_dependencies","text":"provide_filter_dependencies ( created_filter = Dependency ( skip_validation = True ), updated_filter = Dependency ( skip_validation = True ), id_filter = Dependency ( skip_validation = True ), limit_offset = Dependency ( skip_validation = True ), ) Inject filtering dependencies. Add all filters to any route by including this function as a dependency, e.g: @get def get_collection_handler ( filters : Filters ) -> ... : ... The dependency is provided at the application layer, so only need to inject the dependency where it is required. Parameters: Name Type Description Default id_filter CollectionFilter [ UUID ] Filter for scoping query to limited set of identities. Dependency(skip_validation=True) created_filter BeforeAfter Filter for scoping query to instance creation date/time. Dependency(skip_validation=True) updated_filter BeforeAfter Filter for scoping query to instance update date/time. Dependency(skip_validation=True) limit_offset LimitOffset Filter for query pagination. Dependency(skip_validation=True) Returns: Type Description list [ FilterTypes ] List of filters parsed from connection.","title":"provide_filter_dependencies()"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.provide_id_filter","text":"provide_id_filter ( ids = Parameter ( query = 'ids' , default = None , required = False )) Parameters: Name Type Description Default ids list [ UUID ] | None Parsed out of query params. Parameter(query='ids', default=None, required=False) Returns: Type Description CollectionFilter [ UUID ] Type consumed by AbstractRepository.filter_in_collection()","title":"provide_id_filter()"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.provide_limit_offset_pagination","text":"provide_limit_offset_pagination ( page = Parameter ( ge = 1 , default = 1 , required = False ), page_size = Parameter ( query = \"page-size\" , ge = 1 , default = settings . api . DEFAULT_PAGINATION_LIMIT , required = False ), ) Parameters: Name Type Description Default page int LIMIT to apply to select. Parameter(ge=1, default=1, required=False) page_size int OFFSET to apply to select. Parameter(query='page-size', ge=1, default=settings.api.DEFAULT_PAGINATION_LIMIT, required=False) Returns: Type Description LimitOffset Type consumed by Repository.apply_limit_offset_pagination() .","title":"provide_limit_offset_pagination()"},{"location":"reference/starlite_saqlalchemy/dependencies/#starlite_saqlalchemy.dependencies.provide_updated_filter","text":"provide_updated_filter ( before = Parameter ( query = \"updated-before\" , default = None , required = False ), after = Parameter ( query = \"updated-after\" , default = None , required = False ), ) Parameters: Name Type Description Default before DTorNone Filter for records updated before this date/time. Parameter(query='updated-before', default=None, required=False) after DTorNone Filter for records updated after this date/time. Parameter(query='updated-after', default=None, required=False) Returns: Type Description BeforeAfter Type consumed by Repository.filter_on_datetime_field() .","title":"provide_updated_filter()"},{"location":"reference/starlite_saqlalchemy/endpoint_decorator/","text":"Attribution for @endpoint decorator pattern. Sourced from api-client and the following license applies to that original code Copyright (c) 2018 The Python Packaging Authority Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. endpoint \u00b6 endpoint ( cls_ = None , base_url = None ) Construct URL from a base and defined resource. >>> @endpoint(base_url=\"https://somewhere.com\") ... class Endpoints: ... path = \"/path\" ... >>> assert Endpoints.path == \"https://somewhere.com/path\"","title":"endpoint_decorator"},{"location":"reference/starlite_saqlalchemy/endpoint_decorator/#starlite_saqlalchemy.endpoint_decorator.endpoint","text":"endpoint ( cls_ = None , base_url = None ) Construct URL from a base and defined resource. >>> @endpoint(base_url=\"https://somewhere.com\") ... class Endpoints: ... path = \"/path\" ... >>> assert Endpoints.path == \"https://somewhere.com/path\"","title":"endpoint()"},{"location":"reference/starlite_saqlalchemy/exceptions/","text":"Definition of extra HTTP exceptions that aren't included in Starlite . Also, defines functions that translate service and repository exceptions into HTTP exceptions. AuthorizationError \u00b6 Bases: StarliteSaqlalchemyClientError A user tried to do something they shouldn't have. ConflictError \u00b6 Bases: StarliteSaqlalchemyClientError Exception for data integrity errors. HealthCheckConfigurationError \u00b6 Bases: StarliteSaqlalchemyError An error occurred while registering an health check. NotFoundError \u00b6 Bases: StarliteSaqlalchemyClientError Referenced identity doesn't exist. StarliteSaqlalchemyClientError \u00b6 Bases: StarliteSaqlalchemyError Base exception type for client errors. StarliteSaqlalchemyError \u00b6 Bases: Exception Base exception type for the lib's custom exception types. after_exception_hook_handler async \u00b6 after_exception_hook_handler ( exc , _scope , _state ) Binds exc_info key with exception instance as value to structlog context vars. This must be a coroutine so that it is not wrapped in a thread where we'll lose context. Parameters: Name Type Description Default exc Exception the exception that was raised. required _scope Scope scope of the request required _state State application state required starlite_saqlalchemy_exception_to_http_response \u00b6 starlite_saqlalchemy_exception_to_http_response ( request , exc ) Transform repository exceptions to HTTP exceptions. Parameters: Name Type Description Default request Request [ Any , Any ] The request that experienced the exception. required exc StarliteSaqlalchemyError Exception raised during handling of the request. required Returns: Type Description Response [ ExceptionResponseContent ] Exception response appropriate to the type of original exception.","title":"exceptions"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.AuthorizationError","text":"Bases: StarliteSaqlalchemyClientError A user tried to do something they shouldn't have.","title":"AuthorizationError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.ConflictError","text":"Bases: StarliteSaqlalchemyClientError Exception for data integrity errors.","title":"ConflictError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.HealthCheckConfigurationError","text":"Bases: StarliteSaqlalchemyError An error occurred while registering an health check.","title":"HealthCheckConfigurationError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.NotFoundError","text":"Bases: StarliteSaqlalchemyClientError Referenced identity doesn't exist.","title":"NotFoundError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.StarliteSaqlalchemyClientError","text":"Bases: StarliteSaqlalchemyError Base exception type for client errors.","title":"StarliteSaqlalchemyClientError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.StarliteSaqlalchemyError","text":"Bases: Exception Base exception type for the lib's custom exception types.","title":"StarliteSaqlalchemyError"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.after_exception_hook_handler","text":"after_exception_hook_handler ( exc , _scope , _state ) Binds exc_info key with exception instance as value to structlog context vars. This must be a coroutine so that it is not wrapped in a thread where we'll lose context. Parameters: Name Type Description Default exc Exception the exception that was raised. required _scope Scope scope of the request required _state State application state required","title":"after_exception_hook_handler()"},{"location":"reference/starlite_saqlalchemy/exceptions/#starlite_saqlalchemy.exceptions.starlite_saqlalchemy_exception_to_http_response","text":"starlite_saqlalchemy_exception_to_http_response ( request , exc ) Transform repository exceptions to HTTP exceptions. Parameters: Name Type Description Default request Request [ Any , Any ] The request that experienced the exception. required exc StarliteSaqlalchemyError Exception raised during handling of the request. required Returns: Type Description Response [ ExceptionResponseContent ] Exception response appropriate to the type of original exception.","title":"starlite_saqlalchemy_exception_to_http_response()"},{"location":"reference/starlite_saqlalchemy/health/","text":"Health check handler for the application. Returns the app settings as details if successful, otherwise a 503. AbstractHealthCheck \u00b6 Bases: ABC Base protocol for implementing health checks. live async \u00b6 live () Run a liveness check. Returns: Type Description bool True if the service is running, False otherwise ready async abstractmethod \u00b6 ready () Run readiness check. Returns: Type Description bool True if the service is ready to serve requests, False otherwise AppHealthCheck \u00b6 Bases: AbstractHealthCheck Simple health check that does not require any dependencies. ready async \u00b6 ready () Readiness check used when no other health check is available. HealthCheckFailure \u00b6 HealthCheckFailure ( health , * args , detail = '' , status_code = None , headers = None , extra = None ) Bases: ServiceUnavailableException Raise for health check failure. HealthController \u00b6 Bases: Controller Holds health endpoints. health_check async \u00b6 health_check () Run registered health checks. HealthResource \u00b6 Bases: BaseModel Health data returned by the health endpoint. health_failure_exception_handler \u00b6 health_failure_exception_handler ( _ , exc ) Return all health checks data on HealthCheckFailure .","title":"health"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.AbstractHealthCheck","text":"Bases: ABC Base protocol for implementing health checks.","title":"AbstractHealthCheck"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.AbstractHealthCheck.live","text":"live () Run a liveness check. Returns: Type Description bool True if the service is running, False otherwise","title":"live()"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.AbstractHealthCheck.ready","text":"ready () Run readiness check. Returns: Type Description bool True if the service is ready to serve requests, False otherwise","title":"ready()"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.AppHealthCheck","text":"Bases: AbstractHealthCheck Simple health check that does not require any dependencies.","title":"AppHealthCheck"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.AppHealthCheck.ready","text":"ready () Readiness check used when no other health check is available.","title":"ready()"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.HealthCheckFailure","text":"HealthCheckFailure ( health , * args , detail = '' , status_code = None , headers = None , extra = None ) Bases: ServiceUnavailableException Raise for health check failure.","title":"HealthCheckFailure"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.HealthController","text":"Bases: Controller Holds health endpoints.","title":"HealthController"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.HealthController.health_check","text":"health_check () Run registered health checks.","title":"health_check()"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.HealthResource","text":"Bases: BaseModel Health data returned by the health endpoint.","title":"HealthResource"},{"location":"reference/starlite_saqlalchemy/health/#starlite_saqlalchemy.health.health_failure_exception_handler","text":"health_failure_exception_handler ( _ , exc ) Return all health checks data on HealthCheckFailure .","title":"health_failure_exception_handler()"},{"location":"reference/starlite_saqlalchemy/http/","text":"Async HTTP request client implementation built on httpx . clients module-attribute \u00b6 clients = set [ httpx . AsyncClient ]() For bookkeeping of clients. We close them on app shutdown. Client \u00b6 Client ( base_url , headers = None ) A simple HTTP client class with retrying and exponential backoff. This class uses the tenacity library to retry failed HTTP httpx with exponential backoff and jitter. It also uses a httpx.Session instance to manage HTTP connections and cookies. headers: Headers that are applied to every request delete async \u00b6 delete ( path , headers = None ) Make an HTTP DELETE request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP DELETE request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried. get async \u00b6 get ( path , params = None , headers = None ) Make an HTTP GET request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP GET request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required params dict [ str , Any ] | None Query parameters (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried. post async \u00b6 post ( path , content = None , headers = None ) Make an HTTP POST request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP POST request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried. put async \u00b6 put ( path , content = None , headers = None ) Make an HTTP PUT request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP PUT request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried. request async \u00b6 request ( method , path , params = None , content = None , headers = None ) Make an HTTP request with retrying and exponential backoff. This method uses the httpx library to make an HTTP request and the tenacity library to retry the request if it fails. It uses exponential backoff with jitter to wait between retries. Parameters: Name Type Description Default method str The HTTP method (e.g. \"GET\", \"POST\") required path str The URL path (e.g. \"/users/123\") required params dict [ str , Any ] | None Query parameters (optional) None content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried. ClientException \u00b6 Bases: Exception Base client exception. on_shutdown async \u00b6 on_shutdown () Close any clients that have been created.","title":"http"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.clients","text":"clients = set [ httpx . AsyncClient ]() For bookkeeping of clients. We close them on app shutdown.","title":"clients"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client","text":"Client ( base_url , headers = None ) A simple HTTP client class with retrying and exponential backoff. This class uses the tenacity library to retry failed HTTP httpx with exponential backoff and jitter. It also uses a httpx.Session instance to manage HTTP connections and cookies. headers: Headers that are applied to every request","title":"Client"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client.delete","text":"delete ( path , headers = None ) Make an HTTP DELETE request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP DELETE request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried.","title":"delete()"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client.get","text":"get ( path , params = None , headers = None ) Make an HTTP GET request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP GET request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required params dict [ str , Any ] | None Query parameters (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried.","title":"get()"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client.post","text":"post ( path , content = None , headers = None ) Make an HTTP POST request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP POST request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried.","title":"post()"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client.put","text":"put ( path , content = None , headers = None ) Make an HTTP PUT request with retrying and exponential backoff. This method is a convenience wrapper around the request method that sends an HTTP PUT request. Parameters: Name Type Description Default path str The URL path (e.g. \"/users/123\") required content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried.","title":"put()"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.Client.request","text":"request ( method , path , params = None , content = None , headers = None ) Make an HTTP request with retrying and exponential backoff. This method uses the httpx library to make an HTTP request and the tenacity library to retry the request if it fails. It uses exponential backoff with jitter to wait between retries. Parameters: Name Type Description Default method str The HTTP method (e.g. \"GET\", \"POST\") required path str The URL path (e.g. \"/users/123\") required params dict [ str , Any ] | None Query parameters (optional) None content bytes | None Data to send in the request body (optional) None headers dict [ str , str ] | None HTTP headers to send with the request (optional) None Returns: Type Description httpx . Response The httpx.Response object. Raises: Type Description httpx . RequestException If the request fails and cannot be retried.","title":"request()"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.ClientException","text":"Bases: Exception Base client exception.","title":"ClientException"},{"location":"reference/starlite_saqlalchemy/http/#starlite_saqlalchemy.http.on_shutdown","text":"on_shutdown () Close any clients that have been created.","title":"on_shutdown()"},{"location":"reference/starlite_saqlalchemy/init_plugin/","text":"The application configuration plugin and config object. Example from starlite import Starlite , get from starlite_saqlalchemy import ConfigureApp @get ( \"/example\" ) def example_handler () -> dict : return { \"hello\" : \"world\" } app = Starlite ( route_handlers = [ example_handler ], on_app_init = [ ConfigureApp ()]) The plugin can be configured by passing an instance of PluginConfig to ConfigureApp on instantiation app = Starlite ( route_handlers = [ example_handler ], on_app_init [ ConfigureApp ( PluginConfig ( do_openapi = False ))], ) The PluginConfig has switches to disable every aspect of the plugin behavior. ConfigureApp \u00b6 ConfigureApp ( config = PluginConfig ()) Starlite application configuration. __call__ \u00b6 __call__ ( app_config ) Entrypoint to the app config plugin. Receives the AppConfig object and modifies it. Parameters: Name Type Description Default app_config AppConfig Passed to the plugin from the Starlite instance on instantiation. required Returns: Type Description AppConfig The modified AppConfig object. configure_after_exception \u00b6 configure_after_exception ( app_config ) Add the logging after exception hook handler. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_cache \u00b6 configure_cache ( app_config ) Configure the application cache. We only overwrite if DEFAULT_CACHE_CONFIG is the standing configuration object. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_collection_dependencies \u00b6 configure_collection_dependencies ( app_config ) Add the required Provide instances to the app dependency mapping. If a dependency has already been provided with the same key we do not overwrite it. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_compression \u00b6 configure_compression ( app_config ) Configure application compression. No-op if AppConfig.compression_config has already been set. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_debug \u00b6 configure_debug ( app_config ) Set the Starlite debug parameter. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_exception_handlers \u00b6 configure_exception_handlers ( app_config ) Add the handlers that translate service and repository exceptions into HTTP exceptions. Does not overwrite handlers that may already exist for the exception types. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_health_check \u00b6 configure_health_check ( app_config ) Add health check controller. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_logging \u00b6 configure_logging ( app_config ) Configure application logging. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_openapi \u00b6 configure_openapi ( app_config ) Configure the OpenAPI docs. We only overwrite if DEFAULT_OPENAPI_CONFIG is the standing configuration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_sentry \u00b6 configure_sentry ( app_config ) Add handler to configure Sentry integration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_sqlalchemy_plugin \u00b6 configure_sqlalchemy_plugin ( app_config ) Configure SQLAlchemy for the application. Adds a configured SQLAlchemyPlugin to AppConfig.plugins . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_type_encoders \u00b6 configure_type_encoders ( app_config ) Set mapping of type encoders on the application config. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required configure_worker \u00b6 configure_worker ( app_config ) Configure the SAQ async worker. No-op if there are no worker functions set on PluginConfig . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required PluginConfig \u00b6 Bases: BaseModel Configure behavior of the ConfigureApp object. Each feature that the plugin enables can be toggled with the do_<behavior> switch, e.g., PluginConfig(do_after_exception=False) will tell ConfigureApp not to add the after exception logging hook handler to the application. do_after_exception class-attribute \u00b6 do_after_exception : bool = True Configure after exception handler. Add the hook handler to AppConfig.after_exception . do_cache class-attribute \u00b6 do_cache : bool = True Configure redis cache backend. Add configuration for the redis-backed cache to AppConfig.cache_config . do_collection_dependencies class-attribute \u00b6 do_collection_dependencies = True Add collection route dependencies. Add the Provide 's for collection route dependencies to AppConfig.dependencies . do_compression class-attribute \u00b6 do_compression : bool = True Confiture compression backend. Add configuration for gzip compression to AppConfig.compression_config . do_exception_handlers class-attribute \u00b6 do_exception_handlers : bool = True Configure exception handlers. Add the repository/service exception http translation handlers to AppConfig.exception_handlers . do_health_check class-attribute \u00b6 do_health_check : bool = True Configure a health check. Add the health check controller to AppConfig.route_handlers . do_logging class-attribute \u00b6 do_logging : bool = True Configure logging. Set the logging configuration object to AppConfig.logging_config . do_openapi class-attribute \u00b6 do_openapi : bool = True Configure OpenAPI. Set the OpenAPI config object to AppConfig.openapi_config . do_sentry class-attribute \u00b6 do_sentry : bool | None = None Configure sentry. Configure the application to initialize Sentry on startup. Adds a handler to AppConfig.on_startup . do_set_debug class-attribute \u00b6 do_set_debug : bool = True Configure Starlite debug mode. Allow the plugin to set the starlite debug parameter. Parameter set to value of AppConfig.debug . do_sqlalchemy_plugin class-attribute \u00b6 do_sqlalchemy_plugin : bool = True Configure SQLAlchemy plugin. Set the SQLAlchemy plugin on the application. Adds the plugin to AppConfig.plugins . do_type_encoders class-attribute \u00b6 do_type_encoders : bool = True Configure custom type encoders on the app. do_worker class-attribute \u00b6 do_worker : bool = True Configure the async worker on the application. This action instantiates a worker instance and sets handlers for AppConfig.on_startup and AppConfig.on_shutdown that manage the lifecycle of the SAQ worker. log_processors class-attribute \u00b6 log_processors : Sequence [ Processor ] = log . default_processors Chain of structlog log processors. type_encoders class-attribute \u00b6 type_encoders : TypeEncodersMap = type_encoders_map Map of type to serializer callable. worker_functions class-attribute \u00b6 worker_functions : list [ Callable [ ... , Any ] | tuple [ str , Callable [ ... , Any ]]] = [ ( make_service_callback . __qualname__ , make_service_callback ) ] Queue worker functions.","title":"init_plugin"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp","text":"ConfigureApp ( config = PluginConfig ()) Starlite application configuration.","title":"ConfigureApp"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.__call__","text":"__call__ ( app_config ) Entrypoint to the app config plugin. Receives the AppConfig object and modifies it. Parameters: Name Type Description Default app_config AppConfig Passed to the plugin from the Starlite instance on instantiation. required Returns: Type Description AppConfig The modified AppConfig object.","title":"__call__()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_after_exception","text":"configure_after_exception ( app_config ) Add the logging after exception hook handler. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_after_exception()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_cache","text":"configure_cache ( app_config ) Configure the application cache. We only overwrite if DEFAULT_CACHE_CONFIG is the standing configuration object. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_cache()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_collection_dependencies","text":"configure_collection_dependencies ( app_config ) Add the required Provide instances to the app dependency mapping. If a dependency has already been provided with the same key we do not overwrite it. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_collection_dependencies()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_compression","text":"configure_compression ( app_config ) Configure application compression. No-op if AppConfig.compression_config has already been set. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_compression()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_debug","text":"configure_debug ( app_config ) Set the Starlite debug parameter. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_debug()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_exception_handlers","text":"configure_exception_handlers ( app_config ) Add the handlers that translate service and repository exceptions into HTTP exceptions. Does not overwrite handlers that may already exist for the exception types. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_exception_handlers()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_health_check","text":"configure_health_check ( app_config ) Add health check controller. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_health_check()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_logging","text":"configure_logging ( app_config ) Configure application logging. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_logging()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_openapi","text":"configure_openapi ( app_config ) Configure the OpenAPI docs. We only overwrite if DEFAULT_OPENAPI_CONFIG is the standing configuration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_openapi()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_sentry","text":"configure_sentry ( app_config ) Add handler to configure Sentry integration. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_sentry()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_sqlalchemy_plugin","text":"configure_sqlalchemy_plugin ( app_config ) Configure SQLAlchemy for the application. Adds a configured SQLAlchemyPlugin to AppConfig.plugins . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_sqlalchemy_plugin()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_type_encoders","text":"configure_type_encoders ( app_config ) Set mapping of type encoders on the application config. Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_type_encoders()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.ConfigureApp.configure_worker","text":"configure_worker ( app_config ) Configure the SAQ async worker. No-op if there are no worker functions set on PluginConfig . Parameters: Name Type Description Default app_config AppConfig The Starlite application config object. required","title":"configure_worker()"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig","text":"Bases: BaseModel Configure behavior of the ConfigureApp object. Each feature that the plugin enables can be toggled with the do_<behavior> switch, e.g., PluginConfig(do_after_exception=False) will tell ConfigureApp not to add the after exception logging hook handler to the application.","title":"PluginConfig"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_after_exception","text":"do_after_exception : bool = True Configure after exception handler. Add the hook handler to AppConfig.after_exception .","title":"do_after_exception"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_cache","text":"do_cache : bool = True Configure redis cache backend. Add configuration for the redis-backed cache to AppConfig.cache_config .","title":"do_cache"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_collection_dependencies","text":"do_collection_dependencies = True Add collection route dependencies. Add the Provide 's for collection route dependencies to AppConfig.dependencies .","title":"do_collection_dependencies"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_compression","text":"do_compression : bool = True Confiture compression backend. Add configuration for gzip compression to AppConfig.compression_config .","title":"do_compression"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_exception_handlers","text":"do_exception_handlers : bool = True Configure exception handlers. Add the repository/service exception http translation handlers to AppConfig.exception_handlers .","title":"do_exception_handlers"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_health_check","text":"do_health_check : bool = True Configure a health check. Add the health check controller to AppConfig.route_handlers .","title":"do_health_check"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_logging","text":"do_logging : bool = True Configure logging. Set the logging configuration object to AppConfig.logging_config .","title":"do_logging"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_openapi","text":"do_openapi : bool = True Configure OpenAPI. Set the OpenAPI config object to AppConfig.openapi_config .","title":"do_openapi"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_sentry","text":"do_sentry : bool | None = None Configure sentry. Configure the application to initialize Sentry on startup. Adds a handler to AppConfig.on_startup .","title":"do_sentry"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_set_debug","text":"do_set_debug : bool = True Configure Starlite debug mode. Allow the plugin to set the starlite debug parameter. Parameter set to value of AppConfig.debug .","title":"do_set_debug"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_sqlalchemy_plugin","text":"do_sqlalchemy_plugin : bool = True Configure SQLAlchemy plugin. Set the SQLAlchemy plugin on the application. Adds the plugin to AppConfig.plugins .","title":"do_sqlalchemy_plugin"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_type_encoders","text":"do_type_encoders : bool = True Configure custom type encoders on the app.","title":"do_type_encoders"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.do_worker","text":"do_worker : bool = True Configure the async worker on the application. This action instantiates a worker instance and sets handlers for AppConfig.on_startup and AppConfig.on_shutdown that manage the lifecycle of the SAQ worker.","title":"do_worker"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.log_processors","text":"log_processors : Sequence [ Processor ] = log . default_processors Chain of structlog log processors.","title":"log_processors"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.type_encoders","text":"type_encoders : TypeEncodersMap = type_encoders_map Map of type to serializer callable.","title":"type_encoders"},{"location":"reference/starlite_saqlalchemy/init_plugin/#starlite_saqlalchemy.init_plugin.PluginConfig.worker_functions","text":"worker_functions : list [ Callable [ ... , Any ] | tuple [ str , Callable [ ... , Any ]]] = [ ( make_service_callback . __qualname__ , make_service_callback ) ] Queue worker functions.","title":"worker_functions"},{"location":"reference/starlite_saqlalchemy/lifespan/","text":"Application lifespan handlers. before_startup_handler async \u00b6 before_startup_handler ( _ ) Do things before the app starts up.","title":"lifespan"},{"location":"reference/starlite_saqlalchemy/lifespan/#starlite_saqlalchemy.lifespan.before_startup_handler","text":"before_startup_handler ( _ ) Do things before the app starts up.","title":"before_startup_handler()"},{"location":"reference/starlite_saqlalchemy/openapi/","text":"Application OpenAPI config. config module-attribute \u00b6 config = OpenAPIConfig ( title = settings . openapi . TITLE or settings . app . NAME , version = settings . openapi . VERSION , contact = Contact ( name = settings . openapi . CONTACT_NAME , email = settings . openapi . CONTACT_EMAIL ), use_handler_docstrings = True , ) OpenAPI config for app. See OpenAPISettings","title":"openapi"},{"location":"reference/starlite_saqlalchemy/openapi/#starlite_saqlalchemy.openapi.config","text":"config = OpenAPIConfig ( title = settings . openapi . TITLE or settings . app . NAME , version = settings . openapi . VERSION , contact = Contact ( name = settings . openapi . CONTACT_NAME , email = settings . openapi . CONTACT_EMAIL ), use_handler_docstrings = True , ) OpenAPI config for app. See OpenAPISettings","title":"config"},{"location":"reference/starlite_saqlalchemy/redis/","text":"Application redis instance. client module-attribute \u00b6 client : Redis [ bytes ] = Redis . from_url ( settings . redis . URL ) Async Redis instance. Configure via CacheSettings .","title":"redis"},{"location":"reference/starlite_saqlalchemy/redis/#starlite_saqlalchemy.redis.client","text":"client : Redis [ bytes ] = Redis . from_url ( settings . redis . URL ) Async Redis instance. Configure via CacheSettings .","title":"client"},{"location":"reference/starlite_saqlalchemy/scripts/","text":"Application startup script. determine_reload_dirs \u00b6 determine_reload_dirs ( should_reload ) Parameters: Name Type Description Default should_reload bool is reloading enabled? required Returns: Type Description list [ str ] | None List of directories to watch, or None if reloading disabled. determine_should_reload \u00b6 determine_should_reload () Evaluate whether reloading should be enabled. run_app \u00b6 run_app () Run the application with config via environment.","title":"scripts"},{"location":"reference/starlite_saqlalchemy/scripts/#starlite_saqlalchemy.scripts.determine_reload_dirs","text":"determine_reload_dirs ( should_reload ) Parameters: Name Type Description Default should_reload bool is reloading enabled? required Returns: Type Description list [ str ] | None List of directories to watch, or None if reloading disabled.","title":"determine_reload_dirs()"},{"location":"reference/starlite_saqlalchemy/scripts/#starlite_saqlalchemy.scripts.determine_should_reload","text":"determine_should_reload () Evaluate whether reloading should be enabled.","title":"determine_should_reload()"},{"location":"reference/starlite_saqlalchemy/scripts/#starlite_saqlalchemy.scripts.run_app","text":"run_app () Run the application with config via environment.","title":"run_app()"},{"location":"reference/starlite_saqlalchemy/sentry/","text":"Sentry config for our application. SamplingContext \u00b6 Bases: TypedDict Sentry context sent to traces sampler function. configure \u00b6 configure () Configure sentry on app startup. See SentrySettings . sentry_traces_sampler \u00b6 sentry_traces_sampler ( sampling_context ) Don't send health check transactions to sentry.","title":"sentry"},{"location":"reference/starlite_saqlalchemy/sentry/#starlite_saqlalchemy.sentry.SamplingContext","text":"Bases: TypedDict Sentry context sent to traces sampler function.","title":"SamplingContext"},{"location":"reference/starlite_saqlalchemy/sentry/#starlite_saqlalchemy.sentry.configure","text":"configure () Configure sentry on app startup. See SentrySettings .","title":"configure()"},{"location":"reference/starlite_saqlalchemy/sentry/#starlite_saqlalchemy.sentry.sentry_traces_sampler","text":"sentry_traces_sampler ( sampling_context ) Don't send health check transactions to sentry.","title":"sentry_traces_sampler()"},{"location":"reference/starlite_saqlalchemy/service/","text":"A generic service object implementation. Service object is generic on the domain model type. RepositoryService object is generic on the domain model type which should be a SQLAlchemy model. RepositoryService \u00b6 RepositoryService ( ** repo_kwargs ) Bases: Service [ ModelT ] , Generic [ ModelT ] Service object that operates on a repository object. Parameters: Name Type Description Default **repo_kwargs Any passed as keyword args to repo instantiation. {} create async \u00b6 create ( data ) Wrap repository instance creation. Parameters: Name Type Description Default data ModelT Representation to be created. required Returns: Type Description ModelT Representation of created instance. delete async \u00b6 delete ( id_ ) Wrap repository delete operation. Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT Representation of the deleted instance. get async \u00b6 get ( id_ ) Wrap repository scalar operation. Parameters: Name Type Description Default id_ Any Identifier of instance to be retrieved. required Returns: Type Description ModelT Representation of instance with identifier id_ . list async \u00b6 list ( * filters , ** kwargs ) Wrap repository scalars operation. Parameters: Name Type Description Default *filters FilterTypes Collection route filters. () **kwargs Any Keyword arguments for attribute based filtering. {} Returns: Type Description list [ ModelT ] The list of instances retrieved from the repository. new classmethod async \u00b6 new () Context manager that returns instance of service object. Handles construction of the database session. Returns: Type Description AsyncIterator [ RepoServiceT ] The service object instance. update async \u00b6 update ( id_ , data ) Wrap repository update operation. Parameters: Name Type Description Default id_ Any Identifier of item to be updated. required data ModelT Representation to be updated. required Returns: Type Description ModelT Updated representation. upsert async \u00b6 upsert ( id_ , data ) Wrap repository upsert operation. Parameters: Name Type Description Default id_ Any Identifier of the object for upsert. required data ModelT Representation for upsert. required Returns: Type Description ModelT Updated or created representation. Service \u00b6 Bases: Generic [ T ] Generic Service object. __init_subclass__ \u00b6 __init_subclass__ ( * _ , ** __ ) Map the service object to a unique identifier. Important that the id is deterministic across running application instances, e.g., using something like hash() or id() won't work as those would be different on different instances of the running application. So we use the full import path to the object. create async \u00b6 create ( data ) Create an instance of T . Parameters: Name Type Description Default data T Representation to be created. required Returns: Type Description T Representation of created instance. delete async \u00b6 delete ( id_ ) Delete T that is identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description T Representation of the deleted instance. enqueue_background_task async \u00b6 enqueue_background_task ( method_name , job_config = None , ** kwargs ) Enqueue an async callback for the operation and data. Parameters: Name Type Description Default method_name str Method on the service object that should be called by the async worker. required job_config JobConfig | None Configuration object to control the job that is enqueued. None **kwargs Any Arguments to be passed to the method when called. Must be JSON serializable. {} get async \u00b6 get ( id_ ) Retrieve a representation of T with that is identified by id_ Parameters: Name Type Description Default id_ Any Identifier of instance to be retrieved. required Returns: Type Description T Representation of instance with identifier id_ . list async \u00b6 list ( ** kwargs ) Return view of the collection of T . Parameters: Name Type Description Default **kwargs Any Keyword arguments for filtering. {} Returns: Type Description list [ T ] The list of instances retrieved from the repository. new classmethod async \u00b6 new () Context manager that returns instance of service object. Returns: Type Description AsyncIterator [ ServiceT ] The service object instance. update async \u00b6 update ( id_ , data ) Update existing instance of T with data . Parameters: Name Type Description Default id_ Any Identifier of item to be updated. required data T Representation to be updated. required Returns: Type Description T Updated representation. upsert async \u00b6 upsert ( id_ , data ) Create or update an instance of T with data . Parameters: Name Type Description Default id_ Any Identifier of the object for upsert. required data T Representation for upsert. required Returns: Type Description T Updated or created representation. make_service_callback async \u00b6 make_service_callback ( _ctx , * , service_type_id , service_method_name , ** kwargs ) Make an async service callback. Parameters: Name Type Description Default _ctx Context the SAQ context required service_type_id str Value of __id__ class var on service type. required service_method_name str Method to be called on the service object. required **kwargs Any Unpacked into the service method call as keyword arguments. {}","title":"service"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService","text":"RepositoryService ( ** repo_kwargs ) Bases: Service [ ModelT ] , Generic [ ModelT ] Service object that operates on a repository object. Parameters: Name Type Description Default **repo_kwargs Any passed as keyword args to repo instantiation. {}","title":"RepositoryService"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.create","text":"create ( data ) Wrap repository instance creation. Parameters: Name Type Description Default data ModelT Representation to be created. required Returns: Type Description ModelT Representation of created instance.","title":"create()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.delete","text":"delete ( id_ ) Wrap repository delete operation. Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT Representation of the deleted instance.","title":"delete()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.get","text":"get ( id_ ) Wrap repository scalar operation. Parameters: Name Type Description Default id_ Any Identifier of instance to be retrieved. required Returns: Type Description ModelT Representation of instance with identifier id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.list","text":"list ( * filters , ** kwargs ) Wrap repository scalars operation. Parameters: Name Type Description Default *filters FilterTypes Collection route filters. () **kwargs Any Keyword arguments for attribute based filtering. {} Returns: Type Description list [ ModelT ] The list of instances retrieved from the repository.","title":"list()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.new","text":"new () Context manager that returns instance of service object. Handles construction of the database session. Returns: Type Description AsyncIterator [ RepoServiceT ] The service object instance.","title":"new()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.update","text":"update ( id_ , data ) Wrap repository update operation. Parameters: Name Type Description Default id_ Any Identifier of item to be updated. required data ModelT Representation to be updated. required Returns: Type Description ModelT Updated representation.","title":"update()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.RepositoryService.upsert","text":"upsert ( id_ , data ) Wrap repository upsert operation. Parameters: Name Type Description Default id_ Any Identifier of the object for upsert. required data ModelT Representation for upsert. required Returns: Type Description ModelT Updated or created representation.","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service","text":"Bases: Generic [ T ] Generic Service object.","title":"Service"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.__init_subclass__","text":"__init_subclass__ ( * _ , ** __ ) Map the service object to a unique identifier. Important that the id is deterministic across running application instances, e.g., using something like hash() or id() won't work as those would be different on different instances of the running application. So we use the full import path to the object.","title":"__init_subclass__()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.create","text":"create ( data ) Create an instance of T . Parameters: Name Type Description Default data T Representation to be created. required Returns: Type Description T Representation of created instance.","title":"create()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.delete","text":"delete ( id_ ) Delete T that is identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description T Representation of the deleted instance.","title":"delete()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.enqueue_background_task","text":"enqueue_background_task ( method_name , job_config = None , ** kwargs ) Enqueue an async callback for the operation and data. Parameters: Name Type Description Default method_name str Method on the service object that should be called by the async worker. required job_config JobConfig | None Configuration object to control the job that is enqueued. None **kwargs Any Arguments to be passed to the method when called. Must be JSON serializable. {}","title":"enqueue_background_task()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.get","text":"get ( id_ ) Retrieve a representation of T with that is identified by id_ Parameters: Name Type Description Default id_ Any Identifier of instance to be retrieved. required Returns: Type Description T Representation of instance with identifier id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.list","text":"list ( ** kwargs ) Return view of the collection of T . Parameters: Name Type Description Default **kwargs Any Keyword arguments for filtering. {} Returns: Type Description list [ T ] The list of instances retrieved from the repository.","title":"list()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.new","text":"new () Context manager that returns instance of service object. Returns: Type Description AsyncIterator [ ServiceT ] The service object instance.","title":"new()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.update","text":"update ( id_ , data ) Update existing instance of T with data . Parameters: Name Type Description Default id_ Any Identifier of item to be updated. required data T Representation to be updated. required Returns: Type Description T Updated representation.","title":"update()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.Service.upsert","text":"upsert ( id_ , data ) Create or update an instance of T with data . Parameters: Name Type Description Default id_ Any Identifier of the object for upsert. required data T Representation for upsert. required Returns: Type Description T Updated or created representation.","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/service/#starlite_saqlalchemy.service.make_service_callback","text":"make_service_callback ( _ctx , * , service_type_id , service_method_name , ** kwargs ) Make an async service callback. Parameters: Name Type Description Default _ctx Context the SAQ context required service_type_id str Value of __id__ class var on service type. required service_method_name str Method to be called on the service object. required **kwargs Any Unpacked into the service method call as keyword arguments. {}","title":"make_service_callback()"},{"location":"reference/starlite_saqlalchemy/settings/","text":"All configuration via environment. Take note of the environment variable prefixes required for each settings class, except AppSettings . api module-attribute \u00b6 api = APISettings . parse_obj ({}) Api settings. app module-attribute \u00b6 app = AppSettings . parse_obj ({}) App settings. db module-attribute \u00b6 db = DatabaseSettings . parse_obj ({}) Database settings. http module-attribute \u00b6 http = HTTPClientSettings . parse_obj ({}) HTTP Client Settings. log module-attribute \u00b6 log = LogSettings . parse_obj ({}) Log settings. openapi module-attribute \u00b6 openapi = OpenAPISettings . parse_obj ({}) Openapi settings. redis module-attribute \u00b6 redis = RedisSettings . parse_obj ({}) Redis settings. sentry module-attribute \u00b6 sentry = SentrySettings . parse_obj ({}) Sentry settings. server module-attribute \u00b6 server = ServerSettings . parse_obj ({}) Server settings. worker module-attribute \u00b6 worker = WorkerSettings . parse_obj ({}) Worker settings. APISettings \u00b6 Bases: BaseSettings API specific configuration. CACHE_EXPIRATION class-attribute \u00b6 CACHE_EXPIRATION : int = 60 Default cache key expiration in seconds. DB_SESSION_DEPENDENCY_KEY class-attribute \u00b6 DB_SESSION_DEPENDENCY_KEY : str = 'db_session' Parameter name for SQLAlchemy session dependency injection. DEFAULT_PAGINATION_LIMIT class-attribute \u00b6 DEFAULT_PAGINATION_LIMIT : int = 100 Max records received for collection routes. DTO_INFO_KEY class-attribute \u00b6 DTO_INFO_KEY : str = 'dto' Key used for DTO field config in SQLAlchemy info dict. HEALTH_PATH class-attribute \u00b6 HEALTH_PATH : str = '/health' Route that the health check is served under. AppSettings \u00b6 Bases: BaseSettings Generic application settings. These settings are returned as json by the healthcheck endpoint, so do not include any sensitive values here, or if you do ensure to exclude them from serialization in the Config object. BUILD_NUMBER class-attribute \u00b6 BUILD_NUMBER : str = '' Identifier for CI build. CHECK_DB_READY class-attribute \u00b6 CHECK_DB_READY : bool = True Check for database readiness on startup. CHECK_REDIS_READY class-attribute \u00b6 CHECK_REDIS_READY : bool = True Check for redis readiness on startup. DEBUG class-attribute \u00b6 DEBUG : bool = False Run Starlite with debug=True . ENVIRONMENT class-attribute \u00b6 ENVIRONMENT : str = 'prod' 'dev', 'prod', etc. LOCAL_ENVIRONMENT_NAME class-attribute \u00b6 LOCAL_ENVIRONMENT_NAME : str = 'local' Value of ENVIRONMENT used to determine if running in local development mode. This should be the value of ENVIRONMENT in your local .env file. NAME class-attribute \u00b6 NAME : str = 'my-starlite-saqlalchemy-app' Application name. TEST_ENVIRONMENT_NAME class-attribute \u00b6 TEST_ENVIRONMENT_NAME : str = 'test' Value of ENVIRONMENT used to determine if running tests. This should be the value of ENVIRONMENT in test.env . slug property \u00b6 slug : str Return a slugified name. Returns: Type Description str self.NAME , all lowercase and hyphens instead of spaces. DatabaseSettings \u00b6 Bases: BaseSettings Configures the database for the application. ECHO class-attribute \u00b6 ECHO : bool = False Enable SQLAlchemy engine logs. ECHO_POOL class-attribute \u00b6 ECHO_POOL : bool | Literal [ 'debug' ] = False Enable SQLAlchemy connection pool logs. POOL_DISABLE class-attribute \u00b6 POOL_DISABLE : bool = False Disable SQLAlchemy pooling, same as setting pool to. NullPool . POOL_MAX_OVERFLOW class-attribute \u00b6 POOL_MAX_OVERFLOW : int = 10 See max_overflow . POOL_SIZE class-attribute \u00b6 POOL_SIZE : int = 5 See pool_size . POOL_TIMEOUT class-attribute \u00b6 POOL_TIMEOUT : int = 30 See timeout . HTTPClientSettings \u00b6 Bases: BaseSettings HTTP Client configurations. LogSettings \u00b6 Bases: BaseSettings Logging config for the application. EXCLUDE_PATHS class-attribute \u00b6 EXCLUDE_PATHS : str = ' \\\\ A(?!x)x' Regex to exclude paths from logging. HTTP_EVENT class-attribute \u00b6 HTTP_EVENT : str = 'HTTP' Log event name for logs from Starlite handlers. INCLUDE_COMPRESSED_BODY class-attribute \u00b6 INCLUDE_COMPRESSED_BODY : bool = False Include 'body' of compressed responses in log output. JOB_FIELDS class-attribute \u00b6 JOB_FIELDS : list [ str ] = [ \"function\" , \"kwargs\" , \"key\" , \"scheduled\" , \"attempts\" , \"completed\" , \"queued\" , \"started\" , \"result\" , \"error\" , ] Attributes of the SAQ. Job to be logged. LEVEL class-attribute \u00b6 LEVEL : int = 20 Stdlib log levels. Only emit logs at this level, or higher. OBFUSCATE_COOKIES class-attribute \u00b6 OBFUSCATE_COOKIES : set [ str ] = { 'session' } Request cookie keys to obfuscate. OBFUSCATE_HEADERS class-attribute \u00b6 OBFUSCATE_HEADERS : set [ str ] = { 'Authorization' , 'X-API-KEY' } Request header keys to obfuscate. REQUEST_FIELDS class-attribute \u00b6 REQUEST_FIELDS : list [ RequestExtractorField ] = [ \"path\" , \"method\" , \"headers\" , \"cookies\" , \"query\" , \"path_params\" , \"body\" , ] Attributes of the Request to be logged. RESPONSE_FIELDS class-attribute \u00b6 RESPONSE_FIELDS : list [ ResponseExtractorField ] = [ 'status_code' , 'cookies' , 'headers' , 'body' ] Attributes of the Response to be logged. SAQ_LEVEL class-attribute \u00b6 SAQ_LEVEL : int = 30 Level to log SAQ logs. SQLALCHEMY_LEVEL class-attribute \u00b6 SQLALCHEMY_LEVEL : int = 30 Level to log SQLAlchemy logs. UVICORN_ACCESS_LEVEL class-attribute \u00b6 UVICORN_ACCESS_LEVEL : int = 30 Level to log uvicorn access logs. UVICORN_ERROR_LEVEL class-attribute \u00b6 UVICORN_ERROR_LEVEL : int = 20 Level to log uvicorn error logs. WORKER_EVENT class-attribute \u00b6 WORKER_EVENT : str = 'Worker' Log event name for logs from SAQ worker. OpenAPISettings \u00b6 Bases: BaseSettings Configures OpenAPI for the application. CONTACT_EMAIL class-attribute \u00b6 CONTACT_EMAIL : str = 'peter.github@proton.me' Email for contact on document. CONTACT_NAME class-attribute \u00b6 CONTACT_NAME : str = 'Peter' Name of contact on document. TITLE class-attribute \u00b6 TITLE : str | None = 'My Starlite-SAQAlchemy App' Document title. VERSION class-attribute \u00b6 VERSION : str = 'v1.0' Document version. RedisSettings \u00b6 Bases: BaseSettings Redis settings for the application. URL class-attribute \u00b6 URL : AnyUrl = parse_obj_as ( AnyUrl , 'redis://localhost:6379/0' ) A Redis connection URL. SentrySettings \u00b6 Bases: BaseSettings Configures sentry for the application. DSN class-attribute \u00b6 DSN : str = '' The sentry DSN. Set as empty string to disable sentry reporting. TRACES_SAMPLE_RATE class-attribute \u00b6 TRACES_SAMPLE_RATE : float = 0.0001 % of requests traced by sentry, 0.0 means none, 1.0 means all. ServerSettings \u00b6 Bases: BaseSettings Server configurations. APP_LOC class-attribute \u00b6 APP_LOC : str = 'app.main:create_app' Path to app executable, or factory. APP_LOC_IS_FACTORY class-attribute \u00b6 APP_LOC_IS_FACTORY : bool = True Indicate if APP_LOC points to an executable or factory. HOST class-attribute \u00b6 HOST : str = 'localhost' Server network host. KEEPALIVE class-attribute \u00b6 KEEPALIVE : int = 65 Seconds to hold connections open (65 is > AWS lb idle timeout). PORT class-attribute \u00b6 PORT : int = 8000 Server port. RELOAD class-attribute \u00b6 RELOAD : bool | None = None Turn on hot reloading. RELOAD_DIRS class-attribute \u00b6 RELOAD_DIRS : list [ str ] = [ 'src/' ] Directories to watch for reloading. WorkerSettings \u00b6 Bases: BaseSettings Global SAQ Job configuration. JOB_HEARTBEAT class-attribute \u00b6 JOB_HEARTBEAT : int = 0 Max time a job can survive without emitting a heartbeat. 0 to disable. job.update() will trigger a heartbeat. JOB_RETRIES class-attribute \u00b6 JOB_RETRIES : int = 10 Max attempts for any job. JOB_RETRY_BACKOFF class-attribute \u00b6 JOB_RETRY_BACKOFF : bool | float = 60 If true, use exponential backoff for retry delays. The first retry will have whatever retry_delay is. The second retry will have retry_delay 2. The third retry will have retry_delay 4. And so on. This always includes jitter, where the final retry delay is a random number between 0 and the calculated retry delay. If retry_backoff is set to a number, that number is the maximum retry delay, in seconds.\" JOB_RETRY_DELAY class-attribute \u00b6 JOB_RETRY_DELAY : float = 1.0 Seconds to delay before retrying a job. JOB_TIMEOUT class-attribute \u00b6 JOB_TIMEOUT : int = 10 Max time a job can run for, in seconds. Set to 0 for no timeout. JOB_TTL class-attribute \u00b6 JOB_TTL : int = 600 Lifetime of available job information, in seconds. 0: indefinite -1: disabled (no info retained)","title":"settings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.api","text":"api = APISettings . parse_obj ({}) Api settings.","title":"api"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.app","text":"app = AppSettings . parse_obj ({}) App settings.","title":"app"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.db","text":"db = DatabaseSettings . parse_obj ({}) Database settings.","title":"db"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.http","text":"http = HTTPClientSettings . parse_obj ({}) HTTP Client Settings.","title":"http"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.log","text":"log = LogSettings . parse_obj ({}) Log settings.","title":"log"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.openapi","text":"openapi = OpenAPISettings . parse_obj ({}) Openapi settings.","title":"openapi"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.redis","text":"redis = RedisSettings . parse_obj ({}) Redis settings.","title":"redis"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.sentry","text":"sentry = SentrySettings . parse_obj ({}) Sentry settings.","title":"sentry"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.server","text":"server = ServerSettings . parse_obj ({}) Server settings.","title":"server"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.worker","text":"worker = WorkerSettings . parse_obj ({}) Worker settings.","title":"worker"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings","text":"Bases: BaseSettings API specific configuration.","title":"APISettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings.CACHE_EXPIRATION","text":"CACHE_EXPIRATION : int = 60 Default cache key expiration in seconds.","title":"CACHE_EXPIRATION"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings.DB_SESSION_DEPENDENCY_KEY","text":"DB_SESSION_DEPENDENCY_KEY : str = 'db_session' Parameter name for SQLAlchemy session dependency injection.","title":"DB_SESSION_DEPENDENCY_KEY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings.DEFAULT_PAGINATION_LIMIT","text":"DEFAULT_PAGINATION_LIMIT : int = 100 Max records received for collection routes.","title":"DEFAULT_PAGINATION_LIMIT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings.DTO_INFO_KEY","text":"DTO_INFO_KEY : str = 'dto' Key used for DTO field config in SQLAlchemy info dict.","title":"DTO_INFO_KEY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.APISettings.HEALTH_PATH","text":"HEALTH_PATH : str = '/health' Route that the health check is served under.","title":"HEALTH_PATH"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings","text":"Bases: BaseSettings Generic application settings. These settings are returned as json by the healthcheck endpoint, so do not include any sensitive values here, or if you do ensure to exclude them from serialization in the Config object.","title":"AppSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.BUILD_NUMBER","text":"BUILD_NUMBER : str = '' Identifier for CI build.","title":"BUILD_NUMBER"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.CHECK_DB_READY","text":"CHECK_DB_READY : bool = True Check for database readiness on startup.","title":"CHECK_DB_READY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.CHECK_REDIS_READY","text":"CHECK_REDIS_READY : bool = True Check for redis readiness on startup.","title":"CHECK_REDIS_READY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.DEBUG","text":"DEBUG : bool = False Run Starlite with debug=True .","title":"DEBUG"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.ENVIRONMENT","text":"ENVIRONMENT : str = 'prod' 'dev', 'prod', etc.","title":"ENVIRONMENT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.LOCAL_ENVIRONMENT_NAME","text":"LOCAL_ENVIRONMENT_NAME : str = 'local' Value of ENVIRONMENT used to determine if running in local development mode. This should be the value of ENVIRONMENT in your local .env file.","title":"LOCAL_ENVIRONMENT_NAME"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.NAME","text":"NAME : str = 'my-starlite-saqlalchemy-app' Application name.","title":"NAME"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.TEST_ENVIRONMENT_NAME","text":"TEST_ENVIRONMENT_NAME : str = 'test' Value of ENVIRONMENT used to determine if running tests. This should be the value of ENVIRONMENT in test.env .","title":"TEST_ENVIRONMENT_NAME"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.AppSettings.slug","text":"slug : str Return a slugified name. Returns: Type Description str self.NAME , all lowercase and hyphens instead of spaces.","title":"slug"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings","text":"Bases: BaseSettings Configures the database for the application.","title":"DatabaseSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.ECHO","text":"ECHO : bool = False Enable SQLAlchemy engine logs.","title":"ECHO"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.ECHO_POOL","text":"ECHO_POOL : bool | Literal [ 'debug' ] = False Enable SQLAlchemy connection pool logs.","title":"ECHO_POOL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.POOL_DISABLE","text":"POOL_DISABLE : bool = False Disable SQLAlchemy pooling, same as setting pool to. NullPool .","title":"POOL_DISABLE"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.POOL_MAX_OVERFLOW","text":"POOL_MAX_OVERFLOW : int = 10 See max_overflow .","title":"POOL_MAX_OVERFLOW"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.POOL_SIZE","text":"POOL_SIZE : int = 5 See pool_size .","title":"POOL_SIZE"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.DatabaseSettings.POOL_TIMEOUT","text":"POOL_TIMEOUT : int = 30 See timeout .","title":"POOL_TIMEOUT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.HTTPClientSettings","text":"Bases: BaseSettings HTTP Client configurations.","title":"HTTPClientSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings","text":"Bases: BaseSettings Logging config for the application.","title":"LogSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.EXCLUDE_PATHS","text":"EXCLUDE_PATHS : str = ' \\\\ A(?!x)x' Regex to exclude paths from logging.","title":"EXCLUDE_PATHS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.HTTP_EVENT","text":"HTTP_EVENT : str = 'HTTP' Log event name for logs from Starlite handlers.","title":"HTTP_EVENT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.INCLUDE_COMPRESSED_BODY","text":"INCLUDE_COMPRESSED_BODY : bool = False Include 'body' of compressed responses in log output.","title":"INCLUDE_COMPRESSED_BODY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.JOB_FIELDS","text":"JOB_FIELDS : list [ str ] = [ \"function\" , \"kwargs\" , \"key\" , \"scheduled\" , \"attempts\" , \"completed\" , \"queued\" , \"started\" , \"result\" , \"error\" , ] Attributes of the SAQ. Job to be logged.","title":"JOB_FIELDS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.LEVEL","text":"LEVEL : int = 20 Stdlib log levels. Only emit logs at this level, or higher.","title":"LEVEL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.OBFUSCATE_COOKIES","text":"OBFUSCATE_COOKIES : set [ str ] = { 'session' } Request cookie keys to obfuscate.","title":"OBFUSCATE_COOKIES"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.OBFUSCATE_HEADERS","text":"OBFUSCATE_HEADERS : set [ str ] = { 'Authorization' , 'X-API-KEY' } Request header keys to obfuscate.","title":"OBFUSCATE_HEADERS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.REQUEST_FIELDS","text":"REQUEST_FIELDS : list [ RequestExtractorField ] = [ \"path\" , \"method\" , \"headers\" , \"cookies\" , \"query\" , \"path_params\" , \"body\" , ] Attributes of the Request to be logged.","title":"REQUEST_FIELDS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.RESPONSE_FIELDS","text":"RESPONSE_FIELDS : list [ ResponseExtractorField ] = [ 'status_code' , 'cookies' , 'headers' , 'body' ] Attributes of the Response to be logged.","title":"RESPONSE_FIELDS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.SAQ_LEVEL","text":"SAQ_LEVEL : int = 30 Level to log SAQ logs.","title":"SAQ_LEVEL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.SQLALCHEMY_LEVEL","text":"SQLALCHEMY_LEVEL : int = 30 Level to log SQLAlchemy logs.","title":"SQLALCHEMY_LEVEL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.UVICORN_ACCESS_LEVEL","text":"UVICORN_ACCESS_LEVEL : int = 30 Level to log uvicorn access logs.","title":"UVICORN_ACCESS_LEVEL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.UVICORN_ERROR_LEVEL","text":"UVICORN_ERROR_LEVEL : int = 20 Level to log uvicorn error logs.","title":"UVICORN_ERROR_LEVEL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.LogSettings.WORKER_EVENT","text":"WORKER_EVENT : str = 'Worker' Log event name for logs from SAQ worker.","title":"WORKER_EVENT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.OpenAPISettings","text":"Bases: BaseSettings Configures OpenAPI for the application.","title":"OpenAPISettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.OpenAPISettings.CONTACT_EMAIL","text":"CONTACT_EMAIL : str = 'peter.github@proton.me' Email for contact on document.","title":"CONTACT_EMAIL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.OpenAPISettings.CONTACT_NAME","text":"CONTACT_NAME : str = 'Peter' Name of contact on document.","title":"CONTACT_NAME"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.OpenAPISettings.TITLE","text":"TITLE : str | None = 'My Starlite-SAQAlchemy App' Document title.","title":"TITLE"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.OpenAPISettings.VERSION","text":"VERSION : str = 'v1.0' Document version.","title":"VERSION"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.RedisSettings","text":"Bases: BaseSettings Redis settings for the application.","title":"RedisSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.RedisSettings.URL","text":"URL : AnyUrl = parse_obj_as ( AnyUrl , 'redis://localhost:6379/0' ) A Redis connection URL.","title":"URL"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.SentrySettings","text":"Bases: BaseSettings Configures sentry for the application.","title":"SentrySettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.SentrySettings.DSN","text":"DSN : str = '' The sentry DSN. Set as empty string to disable sentry reporting.","title":"DSN"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.SentrySettings.TRACES_SAMPLE_RATE","text":"TRACES_SAMPLE_RATE : float = 0.0001 % of requests traced by sentry, 0.0 means none, 1.0 means all.","title":"TRACES_SAMPLE_RATE"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings","text":"Bases: BaseSettings Server configurations.","title":"ServerSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.APP_LOC","text":"APP_LOC : str = 'app.main:create_app' Path to app executable, or factory.","title":"APP_LOC"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.APP_LOC_IS_FACTORY","text":"APP_LOC_IS_FACTORY : bool = True Indicate if APP_LOC points to an executable or factory.","title":"APP_LOC_IS_FACTORY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.HOST","text":"HOST : str = 'localhost' Server network host.","title":"HOST"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.KEEPALIVE","text":"KEEPALIVE : int = 65 Seconds to hold connections open (65 is > AWS lb idle timeout).","title":"KEEPALIVE"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.PORT","text":"PORT : int = 8000 Server port.","title":"PORT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.RELOAD","text":"RELOAD : bool | None = None Turn on hot reloading.","title":"RELOAD"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.ServerSettings.RELOAD_DIRS","text":"RELOAD_DIRS : list [ str ] = [ 'src/' ] Directories to watch for reloading.","title":"RELOAD_DIRS"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings","text":"Bases: BaseSettings Global SAQ Job configuration.","title":"WorkerSettings"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_HEARTBEAT","text":"JOB_HEARTBEAT : int = 0 Max time a job can survive without emitting a heartbeat. 0 to disable. job.update() will trigger a heartbeat.","title":"JOB_HEARTBEAT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_RETRIES","text":"JOB_RETRIES : int = 10 Max attempts for any job.","title":"JOB_RETRIES"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_RETRY_BACKOFF","text":"JOB_RETRY_BACKOFF : bool | float = 60 If true, use exponential backoff for retry delays. The first retry will have whatever retry_delay is. The second retry will have retry_delay 2. The third retry will have retry_delay 4. And so on. This always includes jitter, where the final retry delay is a random number between 0 and the calculated retry delay. If retry_backoff is set to a number, that number is the maximum retry delay, in seconds.\"","title":"JOB_RETRY_BACKOFF"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_RETRY_DELAY","text":"JOB_RETRY_DELAY : float = 1.0 Seconds to delay before retrying a job.","title":"JOB_RETRY_DELAY"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_TIMEOUT","text":"JOB_TIMEOUT : int = 10 Max time a job can run for, in seconds. Set to 0 for no timeout.","title":"JOB_TIMEOUT"},{"location":"reference/starlite_saqlalchemy/settings/#starlite_saqlalchemy.settings.WorkerSettings.JOB_TTL","text":"JOB_TTL : int = 600 Lifetime of available job information, in seconds. 0: indefinite -1: disabled (no info retained)","title":"JOB_TTL"},{"location":"reference/starlite_saqlalchemy/sqlalchemy_plugin/","text":"Database connectivity and transaction management for the application. SQLAlchemyHealthCheck \u00b6 SQLAlchemyHealthCheck () Bases: AbstractHealthCheck SQLAlchemy health check. ready async \u00b6 ready () Perform a health check on the database. Returns: Type Description bool True if healthy. before_send_handler async \u00b6 before_send_handler ( message , _ , scope ) Inspect status of response and commit, or rolls back. Parameters: Name Type Description Default message Message ASGI message required _ State required scope Scope ASGI scope required","title":"sqlalchemy_plugin"},{"location":"reference/starlite_saqlalchemy/sqlalchemy_plugin/#starlite_saqlalchemy.sqlalchemy_plugin.SQLAlchemyHealthCheck","text":"SQLAlchemyHealthCheck () Bases: AbstractHealthCheck SQLAlchemy health check.","title":"SQLAlchemyHealthCheck"},{"location":"reference/starlite_saqlalchemy/sqlalchemy_plugin/#starlite_saqlalchemy.sqlalchemy_plugin.SQLAlchemyHealthCheck.ready","text":"ready () Perform a health check on the database. Returns: Type Description bool True if healthy.","title":"ready()"},{"location":"reference/starlite_saqlalchemy/sqlalchemy_plugin/#starlite_saqlalchemy.sqlalchemy_plugin.before_send_handler","text":"before_send_handler ( message , _ , scope ) Inspect status of response and commit, or rolls back. Parameters: Name Type Description Default message Message ASGI message required _ State required scope Scope ASGI scope required","title":"before_send_handler()"},{"location":"reference/starlite_saqlalchemy/type_encoders/","text":"A mapping of types to serializer callables.","title":"type_encoders"},{"location":"reference/starlite_saqlalchemy/utils/","text":"General utility functions. case_insensitive_string_compare \u00b6 case_insensitive_string_compare ( a , b ) Compare a and b , stripping whitespace and ignoring case. dataclass_as_dict_shallow \u00b6 dataclass_as_dict_shallow ( dataclass , * , exclude_none = False ) Convert a dataclass to dict, without deepcopy.","title":"utils"},{"location":"reference/starlite_saqlalchemy/utils/#starlite_saqlalchemy.utils.case_insensitive_string_compare","text":"case_insensitive_string_compare ( a , b ) Compare a and b , stripping whitespace and ignoring case.","title":"case_insensitive_string_compare()"},{"location":"reference/starlite_saqlalchemy/utils/#starlite_saqlalchemy.utils.dataclass_as_dict_shallow","text":"dataclass_as_dict_shallow ( dataclass , * , exclude_none = False ) Convert a dataclass to dict, without deepcopy.","title":"dataclass_as_dict_shallow()"},{"location":"reference/starlite_saqlalchemy/worker/","text":"SAQ worker and queue. queue module-attribute \u00b6 queue = Queue ( redis . client ) Async worker queue. Queue instance instantiated with redis instance. JobConfig dataclass \u00b6 Configure a Job. Used to configure jobs enqueued via Service.enqueue_background_task() heartbeat class-attribute \u00b6 heartbeat : int = settings . worker . JOB_HEARTBEAT Max time a job can survive without emitting a heartbeat. 0 to disable. job.update() will trigger a heartbeat. key class-attribute \u00b6 key : str | None = None Pass in to control duplicate jobs. queue class-attribute \u00b6 queue : Queue = queue Queue associated with the job. retries class-attribute \u00b6 retries : int = settings . worker . JOB_RETRIES Max attempts for any job. retry_backoff class-attribute \u00b6 retry_backoff : bool | float = settings . worker . JOB_RETRY_BACKOFF If true, use exponential backoff for retry delays. The first retry will have whatever retry_delay is. The second retry will have retry_delay 2. The third retry will have retry_delay 4. And so on. This always includes jitter, where the final retry delay is a random number between 0 and the calculated retry delay. If retry_backoff is set to a number, that number is the maximum retry delay, in seconds.\" retry_delay class-attribute \u00b6 retry_delay : float = settings . worker . JOB_TTL Seconds to delay before retrying a job. timeout class-attribute \u00b6 timeout : int = settings . worker . JOB_TIMEOUT Max time a job can run for, in seconds. Set to 0 for no timeout. ttl class-attribute \u00b6 ttl : int = settings . worker . JOB_TTL Lifetime of available job information, in seconds. 0: indefinite -1: disabled (no info retained) Queue \u00b6 Queue ( * args , ** kwargs ) Bases: saq . Queue Async task queue. Names the queue per the application slug - namespaces SAQ's redis keys to the app. Configures msgspec for JSON serialization/deserialization if not otherwise configured. Parameters: Name Type Description Default *args Any Passed through to saq.Queue.__init__() () **kwargs Any Passed through to saq.Queue.__init__() {} namespace \u00b6 namespace ( key ) Namespace for the Queue. Parameters: Name Type Description Default key str The unique key to use for the namespace. required Returns: Name Type Description str str The worker namespace Worker \u00b6 Bases: saq . Worker Modify behavior of saq worker for orchestration by Starlite. on_app_startup async \u00b6 on_app_startup () Attach the worker to the running event loop. create_worker_instance \u00b6 create_worker_instance ( functions , before_process = None , after_process = None ) Parameters: Name Type Description Default functions Collection [ Callable [..., Any ] | tuple [ str , Callable ]] Functions to be called via the async workers. required before_process Callable [[ dict [ str , Any ]], Awaitable [ Any ]] | None Async function called before a job processes. None after_process Callable [[ dict [ str , Any ]], Awaitable [ Any ]] | None Async function called after a job processes. None Returns: Type Description Worker The worker instance, instantiated with functions .","title":"worker"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.queue","text":"queue = Queue ( redis . client ) Async worker queue. Queue instance instantiated with redis instance.","title":"queue"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig","text":"Configure a Job. Used to configure jobs enqueued via Service.enqueue_background_task()","title":"JobConfig"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.heartbeat","text":"heartbeat : int = settings . worker . JOB_HEARTBEAT Max time a job can survive without emitting a heartbeat. 0 to disable. job.update() will trigger a heartbeat.","title":"heartbeat"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.key","text":"key : str | None = None Pass in to control duplicate jobs.","title":"key"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.queue","text":"queue : Queue = queue Queue associated with the job.","title":"queue"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.retries","text":"retries : int = settings . worker . JOB_RETRIES Max attempts for any job.","title":"retries"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.retry_backoff","text":"retry_backoff : bool | float = settings . worker . JOB_RETRY_BACKOFF If true, use exponential backoff for retry delays. The first retry will have whatever retry_delay is. The second retry will have retry_delay 2. The third retry will have retry_delay 4. And so on. This always includes jitter, where the final retry delay is a random number between 0 and the calculated retry delay. If retry_backoff is set to a number, that number is the maximum retry delay, in seconds.\"","title":"retry_backoff"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.retry_delay","text":"retry_delay : float = settings . worker . JOB_TTL Seconds to delay before retrying a job.","title":"retry_delay"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.timeout","text":"timeout : int = settings . worker . JOB_TIMEOUT Max time a job can run for, in seconds. Set to 0 for no timeout.","title":"timeout"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.JobConfig.ttl","text":"ttl : int = settings . worker . JOB_TTL Lifetime of available job information, in seconds. 0: indefinite -1: disabled (no info retained)","title":"ttl"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.Queue","text":"Queue ( * args , ** kwargs ) Bases: saq . Queue Async task queue. Names the queue per the application slug - namespaces SAQ's redis keys to the app. Configures msgspec for JSON serialization/deserialization if not otherwise configured. Parameters: Name Type Description Default *args Any Passed through to saq.Queue.__init__() () **kwargs Any Passed through to saq.Queue.__init__() {}","title":"Queue"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.Queue.namespace","text":"namespace ( key ) Namespace for the Queue. Parameters: Name Type Description Default key str The unique key to use for the namespace. required Returns: Name Type Description str str The worker namespace","title":"namespace()"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.Worker","text":"Bases: saq . Worker Modify behavior of saq worker for orchestration by Starlite.","title":"Worker"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.Worker.on_app_startup","text":"on_app_startup () Attach the worker to the running event loop.","title":"on_app_startup()"},{"location":"reference/starlite_saqlalchemy/worker/#starlite_saqlalchemy.worker.create_worker_instance","text":"create_worker_instance ( functions , before_process = None , after_process = None ) Parameters: Name Type Description Default functions Collection [ Callable [..., Any ] | tuple [ str , Callable ]] Functions to be called via the async workers. required before_process Callable [[ dict [ str , Any ]], Awaitable [ Any ]] | None Async function called before a job processes. None after_process Callable [[ dict [ str , Any ]], Awaitable [ Any ]] | None Async function called after a job processes. None Returns: Type Description Worker The worker instance, instantiated with functions .","title":"create_worker_instance()"},{"location":"reference/starlite_saqlalchemy/db/","text":"Database connectivity and transaction management for the application. async_session_factory module-attribute \u00b6 async_session_factory : async_sessionmaker [ AsyncSession ] = async_sessionmaker ( engine ) Database session factory. See async_sessionmaker() . engine module-attribute \u00b6 engine = create_async_engine ( settings . db . URL , echo = settings . db . ECHO , echo_pool = settings . db . ECHO_POOL , json_serializer = _msgspec_json_encoder . encode , max_overflow = settings . db . POOL_MAX_OVERFLOW , pool_size = settings . db . POOL_SIZE , pool_timeout = settings . db . POOL_TIMEOUT , poolclass = NullPool if settings . db . POOL_DISABLE else None , ) Database connection engine. Configure via DatabaseSettings . Overrides default JSON serializer to use msgspec . See create_async_engine() for detailed instructions.","title":"db"},{"location":"reference/starlite_saqlalchemy/db/#starlite_saqlalchemy.db.async_session_factory","text":"async_session_factory : async_sessionmaker [ AsyncSession ] = async_sessionmaker ( engine ) Database session factory. See async_sessionmaker() .","title":"async_session_factory"},{"location":"reference/starlite_saqlalchemy/db/#starlite_saqlalchemy.db.engine","text":"engine = create_async_engine ( settings . db . URL , echo = settings . db . ECHO , echo_pool = settings . db . ECHO_POOL , json_serializer = _msgspec_json_encoder . encode , max_overflow = settings . db . POOL_MAX_OVERFLOW , pool_size = settings . db . POOL_SIZE , pool_timeout = settings . db . POOL_TIMEOUT , poolclass = NullPool if settings . db . POOL_DISABLE else None , ) Database connection engine. Configure via DatabaseSettings . Overrides default JSON serializer to use msgspec . See create_async_engine() for detailed instructions.","title":"engine"},{"location":"reference/starlite_saqlalchemy/db/orm/","text":"Application ORM configuration. DTO_KEY module-attribute \u00b6 DTO_KEY = settings . api . DTO_INFO_KEY The key we use to reference dto.DTOField in the SQLAlchemy info dict. convention module-attribute \u00b6 convention = { \"ix\" : \"ix_ %(column_0_label)s \" , \"uq\" : \"uq_ %(table_name)s _ %(column_0_name)s \" , \"ck\" : \"ck_ %(table_name)s _ %(constraint_name)s \" , \"fk\" : \"fk_ %(table_name)s _ %(column_0_name)s _ %(referred_table_name)s \" , \"pk\" : \"pk_ %(table_name)s \" , } Templates for automated constraint name generation. Base \u00b6 Bases: DeclarativeBase Base for all SQLAlchemy declarative models. created class-attribute \u00b6 created : Mapped [ datetime ] = mapped_column ( default = datetime . now , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Date/time of instance creation. id class-attribute \u00b6 id : Mapped [ UUID ] = mapped_column ( default = uuid4 , primary_key = True , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Primary key column. updated class-attribute \u00b6 updated : Mapped [ datetime ] = mapped_column ( default = datetime . now , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Date/time of instance update. __tablename__ \u00b6 __tablename__ () Infer table name from class name. touch_updated_timestamp \u00b6 touch_updated_timestamp ( session , * _ ) Set timestamp on update. Called from SQLAlchemy's before_flush event to bump the updated timestamp on modified instances. Parameters: Name Type Description Default session Session The sync Session instance that underlies the async session. required","title":"orm"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.DTO_KEY","text":"DTO_KEY = settings . api . DTO_INFO_KEY The key we use to reference dto.DTOField in the SQLAlchemy info dict.","title":"DTO_KEY"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.convention","text":"convention = { \"ix\" : \"ix_ %(column_0_label)s \" , \"uq\" : \"uq_ %(table_name)s _ %(column_0_name)s \" , \"ck\" : \"ck_ %(table_name)s _ %(constraint_name)s \" , \"fk\" : \"fk_ %(table_name)s _ %(column_0_name)s _ %(referred_table_name)s \" , \"pk\" : \"pk_ %(table_name)s \" , } Templates for automated constraint name generation.","title":"convention"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.Base","text":"Bases: DeclarativeBase Base for all SQLAlchemy declarative models.","title":"Base"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.Base.created","text":"created : Mapped [ datetime ] = mapped_column ( default = datetime . now , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Date/time of instance creation.","title":"created"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.Base.id","text":"id : Mapped [ UUID ] = mapped_column ( default = uuid4 , primary_key = True , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Primary key column.","title":"id"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.Base.updated","text":"updated : Mapped [ datetime ] = mapped_column ( default = datetime . now , info = { DTO_KEY : dto . DTOField ( mark = dto . Mark . READ_ONLY )} ) Date/time of instance update.","title":"updated"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.Base.__tablename__","text":"__tablename__ () Infer table name from class name.","title":"__tablename__()"},{"location":"reference/starlite_saqlalchemy/db/orm/#starlite_saqlalchemy.db.orm.touch_updated_timestamp","text":"touch_updated_timestamp ( session , * _ ) Set timestamp on update. Called from SQLAlchemy's before_flush event to bump the updated timestamp on modified instances. Parameters: Name Type Description Default session Session The sync Session instance that underlies the async session. required","title":"touch_updated_timestamp()"},{"location":"reference/starlite_saqlalchemy/dto/","text":"Construct Pydantic models from SQLAlchemy ORM types. DTOConfig dataclass \u00b6 Control the generated DTO. exclude class-attribute \u00b6 exclude : set [ str ] = field ( default_factory = set ) Explicitly exclude fields from the generated DTO. purpose class-attribute \u00b6 purpose : Purpose Configure the DTO for \"read\" or \"write\" operations. DTOField dataclass \u00b6 For configuring DTO behavior on SQLAlchemy model fields. mark class-attribute \u00b6 mark : Mark | None = None Mark the field as read-only, or private. pydantic_field class-attribute \u00b6 pydantic_field : FieldInfo | None = None If provided, used for the pydantic model for this attribute. pydantic_type class-attribute \u00b6 pydantic_type : Any | None = None Override the field type on the pydantic model for this attribute. validators class-attribute \u00b6 validators : Iterable [ Callable [[ Any ], Any ]] | None = None Single argument callables that are defined on the DTO as validators for the field. FromMapped \u00b6 Bases: BaseModel , Generic [ AnyDeclarative ] Produce an SQLAlchemy instance with values from a pydantic model. Config \u00b6 Set orm_mode for to_mapped() method. __class_getitem__ \u00b6 __class_getitem__ ( item ) Decorate cls with result from factory() . Parameters: Name Type Description Default item Annotated [ type [ AnyDeclarative ], DTOConfig | Literal ['read', 'write']] Can be either of a SQLAlchemy ORM instance, or a typing.Annotated annotation where the first argument is a SQLAlchemy ORM instance, and the second is an instance of DTOConfig . required Returns: Type Description type [ FromMapped [ AnyDeclarative ]] A new Pydantic model type, with cls as its base class, and additional fields derived type [ FromMapped [ AnyDeclarative ]] from the SQLAlchemy model, respecting any declared configuration. __init_subclass__ \u00b6 __init_subclass__ ( model = None , ** kwargs ) Set __sqla_model__ on type. Parameters: Name Type Description Default model type [ AnyDeclarative ] | None Model represented by the DTO None kwargs Any Passed to super().__init_subclass__() {} to_mapped \u00b6 to_mapped () Create an instance of self.__sqla_model__ Fill the bound SQLAlchemy model recursively with values from this dataclass. Mark \u00b6 Bases: str , Enum For marking column definitions on the domain models. Example: class Model ( Base ): ... updated_at : Mapped [ datetime ] = mapped_column ( info = { \"dto\" : Mark . READ_ONLY }) PRIVATE class-attribute \u00b6 PRIVATE = 'private' To mark a field that can neither be read or updated by clients. READ_ONLY class-attribute \u00b6 READ_ONLY = 'read-only' To mark a field that can be read, but not updated by clients. Purpose \u00b6 Bases: str , Enum For identifying the purpose of a DTO to the factory. The factory will exclude fields marked as private or read-only on the domain model depending on the purpose of the DTO. Example: ReadDTO = dto . factory ( \"AuthorReadDTO\" , Author , purpose = dto . Purpose . READ ) READ class-attribute \u00b6 READ = 'read' To mark a DTO that is to be used to serialize data returned to clients. WRITE class-attribute \u00b6 WRITE = 'write' To mark a DTO that is to deserialize and validate data provided by clients. config \u00b6 config ( purpose , exclude = None ) Parameters: Name Type Description Default purpose Purpose | Literal ['read', 'write'] Is the DTO for parsing \"write\" data, or serializing \"read\" data? required exclude set [ str ] | None Omit fields from dto by key name. None Returns: Type Description DTOConfig DTOConfig object configured per parameters. field \u00b6 field ( mark = None , pydantic_type = None , pydantic_field = None , validators = None ) Create dto.DTOField() wrapped in a dict for SQLAlchemy info field. Parameters: Name Type Description Default mark Mark | Literal ['read-only', 'private'] | None How this field should be treated by the model factory. None pydantic_type Any | None Override the type annotation for this field. None pydantic_field FieldInfo | None Result of Pydantic's DTOField() function. Override the FieldInfo instance used by the generated model. None validators Iterable [ Callable [[ Any ], Any ]] | None Added to the generated model as validators, with allow_reuse=True . None","title":"dto"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.DTOConfig","text":"Control the generated DTO.","title":"DTOConfig"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOConfig.exclude","text":"exclude : set [ str ] = field ( default_factory = set ) Explicitly exclude fields from the generated DTO.","title":"exclude"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOConfig.purpose","text":"purpose : Purpose Configure the DTO for \"read\" or \"write\" operations.","title":"purpose"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.DTOField","text":"For configuring DTO behavior on SQLAlchemy model fields.","title":"DTOField"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOField.mark","text":"mark : Mark | None = None Mark the field as read-only, or private.","title":"mark"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOField.pydantic_field","text":"pydantic_field : FieldInfo | None = None If provided, used for the pydantic model for this attribute.","title":"pydantic_field"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOField.pydantic_type","text":"pydantic_type : Any | None = None Override the field type on the pydantic model for this attribute.","title":"pydantic_type"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.DTOField.validators","text":"validators : Iterable [ Callable [[ Any ], Any ]] | None = None Single argument callables that are defined on the DTO as validators for the field.","title":"validators"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.FromMapped","text":"Bases: BaseModel , Generic [ AnyDeclarative ] Produce an SQLAlchemy instance with values from a pydantic model.","title":"FromMapped"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.from_mapped.FromMapped.Config","text":"Set orm_mode for to_mapped() method.","title":"Config"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.from_mapped.FromMapped.__class_getitem__","text":"__class_getitem__ ( item ) Decorate cls with result from factory() . Parameters: Name Type Description Default item Annotated [ type [ AnyDeclarative ], DTOConfig | Literal ['read', 'write']] Can be either of a SQLAlchemy ORM instance, or a typing.Annotated annotation where the first argument is a SQLAlchemy ORM instance, and the second is an instance of DTOConfig . required Returns: Type Description type [ FromMapped [ AnyDeclarative ]] A new Pydantic model type, with cls as its base class, and additional fields derived type [ FromMapped [ AnyDeclarative ]] from the SQLAlchemy model, respecting any declared configuration.","title":"__class_getitem__()"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.from_mapped.FromMapped.__init_subclass__","text":"__init_subclass__ ( model = None , ** kwargs ) Set __sqla_model__ on type. Parameters: Name Type Description Default model type [ AnyDeclarative ] | None Model represented by the DTO None kwargs Any Passed to super().__init_subclass__() {}","title":"__init_subclass__()"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.from_mapped.FromMapped.to_mapped","text":"to_mapped () Create an instance of self.__sqla_model__ Fill the bound SQLAlchemy model recursively with values from this dataclass.","title":"to_mapped()"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.Mark","text":"Bases: str , Enum For marking column definitions on the domain models. Example: class Model ( Base ): ... updated_at : Mapped [ datetime ] = mapped_column ( info = { \"dto\" : Mark . READ_ONLY })","title":"Mark"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.Mark.PRIVATE","text":"PRIVATE = 'private' To mark a field that can neither be read or updated by clients.","title":"PRIVATE"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.Mark.READ_ONLY","text":"READ_ONLY = 'read-only' To mark a field that can be read, but not updated by clients.","title":"READ_ONLY"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.Purpose","text":"Bases: str , Enum For identifying the purpose of a DTO to the factory. The factory will exclude fields marked as private or read-only on the domain model depending on the purpose of the DTO. Example: ReadDTO = dto . factory ( \"AuthorReadDTO\" , Author , purpose = dto . Purpose . READ )","title":"Purpose"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.Purpose.READ","text":"READ = 'read' To mark a DTO that is to be used to serialize data returned to clients.","title":"READ"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.types.Purpose.WRITE","text":"WRITE = 'write' To mark a DTO that is to deserialize and validate data provided by clients.","title":"WRITE"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.config","text":"config ( purpose , exclude = None ) Parameters: Name Type Description Default purpose Purpose | Literal ['read', 'write'] Is the DTO for parsing \"write\" data, or serializing \"read\" data? required exclude set [ str ] | None Omit fields from dto by key name. None Returns: Type Description DTOConfig DTOConfig object configured per parameters.","title":"config()"},{"location":"reference/starlite_saqlalchemy/dto/#starlite_saqlalchemy.dto.field","text":"field ( mark = None , pydantic_type = None , pydantic_field = None , validators = None ) Create dto.DTOField() wrapped in a dict for SQLAlchemy info field. Parameters: Name Type Description Default mark Mark | Literal ['read-only', 'private'] | None How this field should be treated by the model factory. None pydantic_type Any | None Override the type annotation for this field. None pydantic_field FieldInfo | None Result of Pydantic's DTOField() function. Override the FieldInfo instance used by the generated model. None validators Iterable [ Callable [[ Any ], Any ]] | None Added to the generated model as validators, with allow_reuse=True . None","title":"field()"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/","text":"Using this implementation instead of the starlite.SQLAlchemy plugin DTO as a POC for using the SQLAlchemy model type annotations to build the pydantic model. Also experimenting with marking columns for DTO purposes using the SQLAlchemy.Column.info field, which allows demarcation of fields that should always be private, or read-only at the model declaration layer. FromMapped \u00b6 Bases: BaseModel , Generic [ AnyDeclarative ] Produce an SQLAlchemy instance with values from a pydantic model. Config \u00b6 Set orm_mode for to_mapped() method. __class_getitem__ \u00b6 __class_getitem__ ( item ) Decorate cls with result from factory() . Parameters: Name Type Description Default item Annotated [ type [ AnyDeclarative ], DTOConfig | Literal ['read', 'write']] Can be either of a SQLAlchemy ORM instance, or a typing.Annotated annotation where the first argument is a SQLAlchemy ORM instance, and the second is an instance of DTOConfig . required Returns: Type Description type [ FromMapped [ AnyDeclarative ]] A new Pydantic model type, with cls as its base class, and additional fields derived type [ FromMapped [ AnyDeclarative ]] from the SQLAlchemy model, respecting any declared configuration. __init_subclass__ \u00b6 __init_subclass__ ( model = None , ** kwargs ) Set __sqla_model__ on type. Parameters: Name Type Description Default model type [ AnyDeclarative ] | None Model represented by the DTO None kwargs Any Passed to super().__init_subclass__() {} to_mapped \u00b6 to_mapped () Create an instance of self.__sqla_model__ Fill the bound SQLAlchemy model recursively with values from this dataclass.","title":"from_mapped"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/#starlite_saqlalchemy.dto.from_mapped.FromMapped","text":"Bases: BaseModel , Generic [ AnyDeclarative ] Produce an SQLAlchemy instance with values from a pydantic model.","title":"FromMapped"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/#starlite_saqlalchemy.dto.from_mapped.FromMapped.Config","text":"Set orm_mode for to_mapped() method.","title":"Config"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/#starlite_saqlalchemy.dto.from_mapped.FromMapped.__class_getitem__","text":"__class_getitem__ ( item ) Decorate cls with result from factory() . Parameters: Name Type Description Default item Annotated [ type [ AnyDeclarative ], DTOConfig | Literal ['read', 'write']] Can be either of a SQLAlchemy ORM instance, or a typing.Annotated annotation where the first argument is a SQLAlchemy ORM instance, and the second is an instance of DTOConfig . required Returns: Type Description type [ FromMapped [ AnyDeclarative ]] A new Pydantic model type, with cls as its base class, and additional fields derived type [ FromMapped [ AnyDeclarative ]] from the SQLAlchemy model, respecting any declared configuration.","title":"__class_getitem__()"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/#starlite_saqlalchemy.dto.from_mapped.FromMapped.__init_subclass__","text":"__init_subclass__ ( model = None , ** kwargs ) Set __sqla_model__ on type. Parameters: Name Type Description Default model type [ AnyDeclarative ] | None Model represented by the DTO None kwargs Any Passed to super().__init_subclass__() {}","title":"__init_subclass__()"},{"location":"reference/starlite_saqlalchemy/dto/from_mapped/#starlite_saqlalchemy.dto.from_mapped.FromMapped.to_mapped","text":"to_mapped () Create an instance of self.__sqla_model__ Fill the bound SQLAlchemy model recursively with values from this dataclass.","title":"to_mapped()"},{"location":"reference/starlite_saqlalchemy/dto/types/","text":"DTO domain types. DTOConfig dataclass \u00b6 Control the generated DTO. exclude class-attribute \u00b6 exclude : set [ str ] = field ( default_factory = set ) Explicitly exclude fields from the generated DTO. purpose class-attribute \u00b6 purpose : Purpose Configure the DTO for \"read\" or \"write\" operations. DTOField dataclass \u00b6 For configuring DTO behavior on SQLAlchemy model fields. mark class-attribute \u00b6 mark : Mark | None = None Mark the field as read-only, or private. pydantic_field class-attribute \u00b6 pydantic_field : FieldInfo | None = None If provided, used for the pydantic model for this attribute. pydantic_type class-attribute \u00b6 pydantic_type : Any | None = None Override the field type on the pydantic model for this attribute. validators class-attribute \u00b6 validators : Iterable [ Callable [[ Any ], Any ]] | None = None Single argument callables that are defined on the DTO as validators for the field. Mark \u00b6 Bases: str , Enum For marking column definitions on the domain models. Example: class Model ( Base ): ... updated_at : Mapped [ datetime ] = mapped_column ( info = { \"dto\" : Mark . READ_ONLY }) PRIVATE class-attribute \u00b6 PRIVATE = 'private' To mark a field that can neither be read or updated by clients. READ_ONLY class-attribute \u00b6 READ_ONLY = 'read-only' To mark a field that can be read, but not updated by clients. Purpose \u00b6 Bases: str , Enum For identifying the purpose of a DTO to the factory. The factory will exclude fields marked as private or read-only on the domain model depending on the purpose of the DTO. Example: ReadDTO = dto . factory ( \"AuthorReadDTO\" , Author , purpose = dto . Purpose . READ ) READ class-attribute \u00b6 READ = 'read' To mark a DTO that is to be used to serialize data returned to clients. WRITE class-attribute \u00b6 WRITE = 'write' To mark a DTO that is to deserialize and validate data provided by clients.","title":"types"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOConfig","text":"Control the generated DTO.","title":"DTOConfig"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOConfig.exclude","text":"exclude : set [ str ] = field ( default_factory = set ) Explicitly exclude fields from the generated DTO.","title":"exclude"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOConfig.purpose","text":"purpose : Purpose Configure the DTO for \"read\" or \"write\" operations.","title":"purpose"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOField","text":"For configuring DTO behavior on SQLAlchemy model fields.","title":"DTOField"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOField.mark","text":"mark : Mark | None = None Mark the field as read-only, or private.","title":"mark"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOField.pydantic_field","text":"pydantic_field : FieldInfo | None = None If provided, used for the pydantic model for this attribute.","title":"pydantic_field"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOField.pydantic_type","text":"pydantic_type : Any | None = None Override the field type on the pydantic model for this attribute.","title":"pydantic_type"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.DTOField.validators","text":"validators : Iterable [ Callable [[ Any ], Any ]] | None = None Single argument callables that are defined on the DTO as validators for the field.","title":"validators"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Mark","text":"Bases: str , Enum For marking column definitions on the domain models. Example: class Model ( Base ): ... updated_at : Mapped [ datetime ] = mapped_column ( info = { \"dto\" : Mark . READ_ONLY })","title":"Mark"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Mark.PRIVATE","text":"PRIVATE = 'private' To mark a field that can neither be read or updated by clients.","title":"PRIVATE"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Mark.READ_ONLY","text":"READ_ONLY = 'read-only' To mark a field that can be read, but not updated by clients.","title":"READ_ONLY"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Purpose","text":"Bases: str , Enum For identifying the purpose of a DTO to the factory. The factory will exclude fields marked as private or read-only on the domain model depending on the purpose of the DTO. Example: ReadDTO = dto . factory ( \"AuthorReadDTO\" , Author , purpose = dto . Purpose . READ )","title":"Purpose"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Purpose.READ","text":"READ = 'read' To mark a DTO that is to be used to serialize data returned to clients.","title":"READ"},{"location":"reference/starlite_saqlalchemy/dto/types/#starlite_saqlalchemy.dto.types.Purpose.WRITE","text":"WRITE = 'write' To mark a DTO that is to deserialize and validate data provided by clients.","title":"WRITE"},{"location":"reference/starlite_saqlalchemy/dto/utils/","text":"Things that make working with DTOs nicer. config \u00b6 config ( purpose , exclude = None ) Parameters: Name Type Description Default purpose Purpose | Literal ['read', 'write'] Is the DTO for parsing \"write\" data, or serializing \"read\" data? required exclude set [ str ] | None Omit fields from dto by key name. None Returns: Type Description DTOConfig DTOConfig object configured per parameters. field \u00b6 field ( mark = None , pydantic_type = None , pydantic_field = None , validators = None ) Create dto.DTOField() wrapped in a dict for SQLAlchemy info field. Parameters: Name Type Description Default mark Mark | Literal ['read-only', 'private'] | None How this field should be treated by the model factory. None pydantic_type Any | None Override the type annotation for this field. None pydantic_field FieldInfo | None Result of Pydantic's DTOField() function. Override the FieldInfo instance used by the generated model. None validators Iterable [ Callable [[ Any ], Any ]] | None Added to the generated model as validators, with allow_reuse=True . None","title":"utils"},{"location":"reference/starlite_saqlalchemy/dto/utils/#starlite_saqlalchemy.dto.utils.config","text":"config ( purpose , exclude = None ) Parameters: Name Type Description Default purpose Purpose | Literal ['read', 'write'] Is the DTO for parsing \"write\" data, or serializing \"read\" data? required exclude set [ str ] | None Omit fields from dto by key name. None Returns: Type Description DTOConfig DTOConfig object configured per parameters.","title":"config()"},{"location":"reference/starlite_saqlalchemy/dto/utils/#starlite_saqlalchemy.dto.utils.field","text":"field ( mark = None , pydantic_type = None , pydantic_field = None , validators = None ) Create dto.DTOField() wrapped in a dict for SQLAlchemy info field. Parameters: Name Type Description Default mark Mark | Literal ['read-only', 'private'] | None How this field should be treated by the model factory. None pydantic_type Any | None Override the type annotation for this field. None pydantic_field FieldInfo | None Result of Pydantic's DTOField() function. Override the FieldInfo instance used by the generated model. None validators Iterable [ Callable [[ Any ], Any ]] | None Added to the generated model as validators, with allow_reuse=True . None","title":"field()"},{"location":"reference/starlite_saqlalchemy/log/","text":"All the logging config and things are in here. config module-attribute \u00b6 config = LoggingConfig ( root = { \"level\" : logging . getLevelName ( settings . log . LEVEL ), \"handlers\" : [ \"queue_listener\" ]}, formatters = { \"standard\" : { \"()\" : structlog . stdlib . ProcessorFormatter , \"processors\" : stdlib_processors } }, loggers = { \"uvicorn.access\" : { \"propagate\" : False , \"level\" : settings . log . UVICORN_ACCESS_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"uvicorn.error\" : { \"propagate\" : False , \"level\" : settings . log . UVICORN_ERROR_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"saq\" : { \"propagate\" : False , \"level\" : settings . log . SAQ_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"sqlalchemy.engine\" : { \"propagate\" : False , \"level\" : settings . log . SQLALCHEMY_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, }, ) Pre-configured log config for application deps. While we use structlog for internal app logging, we still want to ensure that logs emitted by any of our dependencies are handled in a non- blocking manner. configure \u00b6 configure ( processors ) Call to configure structlog on app startup. The calls to structlog.get_logger() in controller.py and worker.py return proxies to the logger that is eventually called after this configurator function has been called. Therefore, nothing should try to log via structlog before this is called.","title":"log"},{"location":"reference/starlite_saqlalchemy/log/#starlite_saqlalchemy.log.config","text":"config = LoggingConfig ( root = { \"level\" : logging . getLevelName ( settings . log . LEVEL ), \"handlers\" : [ \"queue_listener\" ]}, formatters = { \"standard\" : { \"()\" : structlog . stdlib . ProcessorFormatter , \"processors\" : stdlib_processors } }, loggers = { \"uvicorn.access\" : { \"propagate\" : False , \"level\" : settings . log . UVICORN_ACCESS_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"uvicorn.error\" : { \"propagate\" : False , \"level\" : settings . log . UVICORN_ERROR_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"saq\" : { \"propagate\" : False , \"level\" : settings . log . SAQ_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, \"sqlalchemy.engine\" : { \"propagate\" : False , \"level\" : settings . log . SQLALCHEMY_LEVEL , \"handlers\" : [ \"queue_listener\" ], }, }, ) Pre-configured log config for application deps. While we use structlog for internal app logging, we still want to ensure that logs emitted by any of our dependencies are handled in a non- blocking manner.","title":"config"},{"location":"reference/starlite_saqlalchemy/log/#starlite_saqlalchemy.log.configure","text":"configure ( processors ) Call to configure structlog on app startup. The calls to structlog.get_logger() in controller.py and worker.py return proxies to the logger that is eventually called after this configurator function has been called. Therefore, nothing should try to log via structlog before this is called.","title":"configure()"},{"location":"reference/starlite_saqlalchemy/log/controller/","text":"Logging config for the application. Ensures that the app, sqlalchemy, saq and uvicorn loggers all log through the queue listener. Adds a filter for health check route logs. BeforeSendHandler \u00b6 BeforeSendHandler () Extraction of request and response data from connection scope. __call__ async \u00b6 __call__ ( message , _ , scope ) Receives ASGI response messages and scope, and logs per configuration. Parameters: Name Type Description Default message Message ASGI response event. required scope Scope ASGI connection scope. required extract_request_data async \u00b6 extract_request_data ( request ) Create a dictionary of values for the log. Parameters: Name Type Description Default request Request A Request instance. required Returns: Type Description dict [ str , Any ] An OrderedDict. extract_response_data \u00b6 extract_response_data ( scope ) Extract data from the response. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description dict [ str , Any ] An OrderedDict. log_request async \u00b6 log_request ( scope ) Handle extracting the request data and logging the message. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description None None log_response async \u00b6 log_response ( scope ) Handle extracting the response data and logging the message. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description None None drop_health_logs \u00b6 drop_health_logs ( _ , __ , event_dict ) Prevent logging of successful health checks. Parameters: Name Type Description Default _ WrappedLogger Wrapped logger object. required __ str Name of the wrapped method, e.g., \"info\", \"warning\", etc. required event_dict EventDict Current context with current event, e.g, {\"a\": 42, \"event\": \"foo\"} . required Returns: Type Description EventDict event_dict for further processing if it does not represent a successful health check. middleware_factory \u00b6 middleware_factory ( app ) Middleware to ensure that every request has a clean structlog context. Parameters: Name Type Description Default app ASGIApp The previous ASGI app in the call chain. required Returns: Type Description ASGIApp A new ASGI app that cleans the structlog contextvars.","title":"controller"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler","text":"BeforeSendHandler () Extraction of request and response data from connection scope.","title":"BeforeSendHandler"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler.__call__","text":"__call__ ( message , _ , scope ) Receives ASGI response messages and scope, and logs per configuration. Parameters: Name Type Description Default message Message ASGI response event. required scope Scope ASGI connection scope. required","title":"__call__()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler.extract_request_data","text":"extract_request_data ( request ) Create a dictionary of values for the log. Parameters: Name Type Description Default request Request A Request instance. required Returns: Type Description dict [ str , Any ] An OrderedDict.","title":"extract_request_data()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler.extract_response_data","text":"extract_response_data ( scope ) Extract data from the response. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description dict [ str , Any ] An OrderedDict.","title":"extract_response_data()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler.log_request","text":"log_request ( scope ) Handle extracting the request data and logging the message. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description None None","title":"log_request()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.BeforeSendHandler.log_response","text":"log_response ( scope ) Handle extracting the response data and logging the message. Parameters: Name Type Description Default scope Scope The ASGI connection scope. required Returns: Type Description None None","title":"log_response()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.drop_health_logs","text":"drop_health_logs ( _ , __ , event_dict ) Prevent logging of successful health checks. Parameters: Name Type Description Default _ WrappedLogger Wrapped logger object. required __ str Name of the wrapped method, e.g., \"info\", \"warning\", etc. required event_dict EventDict Current context with current event, e.g, {\"a\": 42, \"event\": \"foo\"} . required Returns: Type Description EventDict event_dict for further processing if it does not represent a successful health check.","title":"drop_health_logs()"},{"location":"reference/starlite_saqlalchemy/log/controller/#starlite_saqlalchemy.log.controller.middleware_factory","text":"middleware_factory ( app ) Middleware to ensure that every request has a clean structlog context. Parameters: Name Type Description Default app ASGIApp The previous ASGI app in the call chain. required Returns: Type Description ASGIApp A new ASGI app that cleans the structlog contextvars.","title":"middleware_factory()"},{"location":"reference/starlite_saqlalchemy/log/utils/","text":"Logging utilities. msgspec_json_renderer() A JSON Renderer for structlog using msgspec. Msgspec doesn't have an API consistent with the stdlib's `json` module, which is required for structlog's `JSONRenderer`. EventFilter A structlog processor that removes keys from the log event if they exist. EventFilter \u00b6 EventFilter ( filter_keys ) Remove keys from the log event. Add an instance to the processor chain. Examples structlog.configure( ..., processors=[ ..., EventFilter([\"color_message\"]), ..., ] ) __call__ \u00b6 __call__ ( _ , __ , event_dict ) Receive the log event, and filter keys. Parameters: Name Type Description Default _ required __ required event_dict The data to be logged. required Returns: Type Description EventDict The log event with any key in self.filter_keys removed. msgspec_json_renderer \u00b6 msgspec_json_renderer ( _ , __ , event_dict ) Structlog processor that uses msgspec for JSON encoding. Parameters: Name Type Description Default _ required __ required event_dict The data to be logged. required Returns: Type Description bytes The log event encoded to JSON by msgspec.","title":"utils"},{"location":"reference/starlite_saqlalchemy/log/utils/#starlite_saqlalchemy.log.utils.EventFilter","text":"EventFilter ( filter_keys ) Remove keys from the log event. Add an instance to the processor chain. Examples structlog.configure( ..., processors=[ ..., EventFilter([\"color_message\"]), ..., ] )","title":"EventFilter"},{"location":"reference/starlite_saqlalchemy/log/utils/#starlite_saqlalchemy.log.utils.EventFilter.__call__","text":"__call__ ( _ , __ , event_dict ) Receive the log event, and filter keys. Parameters: Name Type Description Default _ required __ required event_dict The data to be logged. required Returns: Type Description EventDict The log event with any key in self.filter_keys removed.","title":"__call__()"},{"location":"reference/starlite_saqlalchemy/log/utils/#starlite_saqlalchemy.log.utils.msgspec_json_renderer","text":"msgspec_json_renderer ( _ , __ , event_dict ) Structlog processor that uses msgspec for JSON encoding. Parameters: Name Type Description Default _ required __ required event_dict The data to be logged. required Returns: Type Description bytes The log event encoded to JSON by msgspec.","title":"msgspec_json_renderer()"},{"location":"reference/starlite_saqlalchemy/log/worker/","text":"Log config and utils for the worker instance. after_process async \u00b6 after_process ( ctx ) Parse log context and log it along with the contextvars context. before_process async \u00b6 before_process ( _ ) Clear the structlog contextvars for this task.","title":"worker"},{"location":"reference/starlite_saqlalchemy/log/worker/#starlite_saqlalchemy.log.worker.after_process","text":"after_process ( ctx ) Parse log context and log it along with the contextvars context.","title":"after_process()"},{"location":"reference/starlite_saqlalchemy/log/worker/#starlite_saqlalchemy.log.worker.before_process","text":"before_process ( _ ) Clear the structlog contextvars for this task.","title":"before_process()"},{"location":"reference/starlite_saqlalchemy/repository/","text":"Abstraction over the data storage for the application.","title":"repository"},{"location":"reference/starlite_saqlalchemy/repository/abc/","text":"Data persistence interface. AbstractRepository \u00b6 AbstractRepository ( ** kwargs ) Bases: Generic [ T ] Interface for persistent data interaction. id_attribute class-attribute \u00b6 id_attribute = 'id' Name of the primary identifying attribute on model_type . model_type class-attribute \u00b6 model_type : type [ T ] Type of object represented by the repository. add async abstractmethod \u00b6 add ( data ) Add data to the collection. Parameters: Name Type Description Default data T Instance to be added to the collection. required Returns: Type Description T The added instance. check_not_found staticmethod \u00b6 check_not_found ( item_or_none ) Raise RepositoryNotFoundException if item_or_none is None . Parameters: Name Type Description Default item_or_none T | None Item to be tested for existence. required Returns: Type Description T The item, if it exists. delete async abstractmethod \u00b6 delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description T The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . filter_collection_by_kwargs abstractmethod \u00b6 filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Has AND semantics where multiple kwargs name/value pairs are provided. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {} Raises: Type Description RepositoryException if a named attribute doesn't exist on self.model_type . get async abstractmethod \u00b6 get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description T The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . get_id_attribute_value classmethod \u00b6 get_id_attribute_value ( item ) Get value of attribute named as self.id_attribute on item . Parameters: Name Type Description Default item T Anything that should have an attribute named as self.id_attribute value. required Returns: Type Description Any The value of attribute on item named as self.id_attribute . list async abstractmethod \u00b6 list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ T ] The list of instances, after filtering applied. set_id_attribute_value classmethod \u00b6 set_id_attribute_value ( id_ , item ) Return the item after the ID is set to the appropriate attribute. Parameters: Name Type Description Default id_ Any Value of ID to be set on instance required item T Anything that should have an attribute named as self.id_attribute value. required Returns: Type Description Any Item with id_ set to cls.id_attribute update async abstractmethod \u00b6 update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data T An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description T The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data . upsert async abstractmethod \u00b6 upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data T Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description T The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"abc"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository","text":"AbstractRepository ( ** kwargs ) Bases: Generic [ T ] Interface for persistent data interaction.","title":"AbstractRepository"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.id_attribute","text":"id_attribute = 'id' Name of the primary identifying attribute on model_type .","title":"id_attribute"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.model_type","text":"model_type : type [ T ] Type of object represented by the repository.","title":"model_type"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.add","text":"add ( data ) Add data to the collection. Parameters: Name Type Description Default data T Instance to be added to the collection. required Returns: Type Description T The added instance.","title":"add()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.check_not_found","text":"check_not_found ( item_or_none ) Raise RepositoryNotFoundException if item_or_none is None . Parameters: Name Type Description Default item_or_none T | None Item to be tested for existence. required Returns: Type Description T The item, if it exists.","title":"check_not_found()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.delete","text":"delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description T The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"delete()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.filter_collection_by_kwargs","text":"filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Has AND semantics where multiple kwargs name/value pairs are provided. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {} Raises: Type Description RepositoryException if a named attribute doesn't exist on self.model_type .","title":"filter_collection_by_kwargs()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.get","text":"get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description T The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.get_id_attribute_value","text":"get_id_attribute_value ( item ) Get value of attribute named as self.id_attribute on item . Parameters: Name Type Description Default item T Anything that should have an attribute named as self.id_attribute value. required Returns: Type Description Any The value of attribute on item named as self.id_attribute .","title":"get_id_attribute_value()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.list","text":"list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ T ] The list of instances, after filtering applied.","title":"list()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.set_id_attribute_value","text":"set_id_attribute_value ( id_ , item ) Return the item after the ID is set to the appropriate attribute. Parameters: Name Type Description Default id_ Any Value of ID to be set on instance required item T Anything that should have an attribute named as self.id_attribute value. required Returns: Type Description Any Item with id_ set to cls.id_attribute","title":"set_id_attribute_value()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.update","text":"update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data T An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description T The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"update()"},{"location":"reference/starlite_saqlalchemy/repository/abc/#starlite_saqlalchemy.repository.abc.AbstractRepository.upsert","text":"upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data T Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description T The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/repository/filters/","text":"Collection filter datastructures. BeforeAfter dataclass \u00b6 Data required to filter a query on a datetime column. after class-attribute \u00b6 after : datetime | None Filter results where field later than this. before class-attribute \u00b6 before : datetime | None Filter results where field earlier than this. field_name class-attribute \u00b6 field_name : str Name of the model attribute to filter on. CollectionFilter dataclass \u00b6 Bases: Generic [ T ] Data required to construct a `WHERE ... IN (...)` clause. field_name class-attribute \u00b6 field_name : str Name of the model attribute to filter on. values class-attribute \u00b6 values : abc . Collection [ T ] Values for IN clause. LimitOffset dataclass \u00b6 Data required to add limit/offset filtering to a query. limit class-attribute \u00b6 limit : int Value for LIMIT clause of query. offset class-attribute \u00b6 offset : int Value for OFFSET clause of query.","title":"filters"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.BeforeAfter","text":"Data required to filter a query on a datetime column.","title":"BeforeAfter"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.BeforeAfter.after","text":"after : datetime | None Filter results where field later than this.","title":"after"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.BeforeAfter.before","text":"before : datetime | None Filter results where field earlier than this.","title":"before"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.BeforeAfter.field_name","text":"field_name : str Name of the model attribute to filter on.","title":"field_name"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.CollectionFilter","text":"Bases: Generic [ T ] Data required to construct a `WHERE ... IN (...)` clause.","title":"CollectionFilter"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.CollectionFilter.field_name","text":"field_name : str Name of the model attribute to filter on.","title":"field_name"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.CollectionFilter.values","text":"values : abc . Collection [ T ] Values for IN clause.","title":"values"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.LimitOffset","text":"Data required to add limit/offset filtering to a query.","title":"LimitOffset"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.LimitOffset.limit","text":"limit : int Value for LIMIT clause of query.","title":"limit"},{"location":"reference/starlite_saqlalchemy/repository/filters/#starlite_saqlalchemy.repository.filters.LimitOffset.offset","text":"offset : int Value for OFFSET clause of query.","title":"offset"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/","text":"SQLAlchemy-based implementation of the repository protocol. SQLAlchemyRepository \u00b6 SQLAlchemyRepository ( * , session , select_ = None , ** kwargs ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] SQLAlchemy based implementation of the repository interface. select_: To facilitate customization of the underlying select query. add async \u00b6 add ( data ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required Returns: Type Description ModelT The added instance. check_health classmethod async \u00b6 check_health ( session ) Perform a health check on the database. Parameters: Name Type Description Default session AsyncSession through which we runa check statement required Returns: Type Description bool True if healthy. delete async \u00b6 delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . filter_collection_by_kwargs \u00b6 filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {} get async \u00b6 get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . list async \u00b6 list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied. update async \u00b6 update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data . upsert async \u00b6 upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data . wrap_sqlalchemy_exception \u00b6 wrap_sqlalchemy_exception () Do something within context to raise a RepositoryException chained from an original SQLAlchemyError . >>> try: ... with wrap_sqlalchemy_exception(): ... raise SQLAlchemyError(\"Original Exception\") ... except StarliteSaqlalchemyError as exc: ... print(f\"caught repository exception from {type(exc.__context__)}\") ... caught repository exception from <class 'sqlalchemy.exc.SQLAlchemyError'>","title":"sqlalchemy"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository","text":"SQLAlchemyRepository ( * , session , select_ = None , ** kwargs ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] SQLAlchemy based implementation of the repository interface. select_: To facilitate customization of the underlying select query.","title":"SQLAlchemyRepository"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.add","text":"add ( data ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required Returns: Type Description ModelT The added instance.","title":"add()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.check_health","text":"check_health ( session ) Perform a health check on the database. Parameters: Name Type Description Default session AsyncSession through which we runa check statement required Returns: Type Description bool True if healthy.","title":"check_health()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.delete","text":"delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"delete()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.filter_collection_by_kwargs","text":"filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {}","title":"filter_collection_by_kwargs()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.get","text":"get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.list","text":"list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied.","title":"list()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.update","text":"update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"update()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.SQLAlchemyRepository.upsert","text":"upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/repository/sqlalchemy/#starlite_saqlalchemy.repository.sqlalchemy.wrap_sqlalchemy_exception","text":"wrap_sqlalchemy_exception () Do something within context to raise a RepositoryException chained from an original SQLAlchemyError . >>> try: ... with wrap_sqlalchemy_exception(): ... raise SQLAlchemyError(\"Original Exception\") ... except StarliteSaqlalchemyError as exc: ... print(f\"caught repository exception from {type(exc.__context__)}\") ... caught repository exception from <class 'sqlalchemy.exc.SQLAlchemyError'>","title":"wrap_sqlalchemy_exception()"},{"location":"reference/starlite_saqlalchemy/repository/types/","text":"Repository type definitions. FilterTypes module-attribute \u00b6 FilterTypes = BeforeAfter | CollectionFilter [ Any ] | LimitOffset Aggregate type alias of the types supported for collection filtering.","title":"types"},{"location":"reference/starlite_saqlalchemy/repository/types/#starlite_saqlalchemy.repository.types.FilterTypes","text":"FilterTypes = BeforeAfter | CollectionFilter [ Any ] | LimitOffset Aggregate type alias of the types supported for collection filtering.","title":"FilterTypes"},{"location":"reference/starlite_saqlalchemy/testing/","text":"Application testing support. ControllerTest \u00b6 ControllerTest ( client , base_path , collection , raw_collection , service_type , monkeypatch , collection_filters = None , ) Standard controller testing utility. Parameters: Name Type Description Default client TestClient Test client instance. required base_path str Path for POST and collection GET requests. required collection Sequence [ orm . Base ] Collection of domain objects. required raw_collection Sequence [ dict [ str , Any ]] Collection of raw representations of domain objects. required service_type type [ Service ] The domain Service object type. required monkeypatch MonkeyPatch Pytest's monkeypatch. required collection_filters dict [ str , Any ] | None Collection filters for GET collection request. None run \u00b6 run () Run the tests. test_get_collection \u00b6 test_get_collection ( with_filters = False ) Test collection endpoint get request. test_member_request \u00b6 test_member_request ( method , service_method , exp_status ) Test member endpoint request. GenericMockRepository \u00b6 GenericMockRepository ( id_factory = uuid4 , ** _ ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] A repository implementation for tests. Uses a dict for storage. __class_getitem__ classmethod \u00b6 __class_getitem__ ( item ) Add collection to _collections for the type. Parameters: Name Type Description Default item type [ ModelT ] The type that the class has been parametrized with. required add async \u00b6 add ( data , allow_id = False ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required allow_id bool disable the identified object check. False Returns: Type Description ModelT The added instance. clear_collection classmethod \u00b6 clear_collection () Empty the collection for repository type. delete async \u00b6 delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . filter_collection_by_kwargs \u00b6 filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {} get async \u00b6 get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . list async \u00b6 list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied. seed_collection classmethod \u00b6 seed_collection ( instances ) Seed the collection for repository type. Parameters: Name Type Description Default instances Iterable [ ModelT ] the instances to be added to the collection. required update async \u00b6 update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data . upsert async \u00b6 upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"testing"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.ControllerTest","text":"ControllerTest ( client , base_path , collection , raw_collection , service_type , monkeypatch , collection_filters = None , ) Standard controller testing utility. Parameters: Name Type Description Default client TestClient Test client instance. required base_path str Path for POST and collection GET requests. required collection Sequence [ orm . Base ] Collection of domain objects. required raw_collection Sequence [ dict [ str , Any ]] Collection of raw representations of domain objects. required service_type type [ Service ] The domain Service object type. required monkeypatch MonkeyPatch Pytest's monkeypatch. required collection_filters dict [ str , Any ] | None Collection filters for GET collection request. None","title":"ControllerTest"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.controller_test.ControllerTest.run","text":"run () Run the tests.","title":"run()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.controller_test.ControllerTest.test_get_collection","text":"test_get_collection ( with_filters = False ) Test collection endpoint get request.","title":"test_get_collection()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.controller_test.ControllerTest.test_member_request","text":"test_member_request ( method , service_method , exp_status ) Test member endpoint request.","title":"test_member_request()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.GenericMockRepository","text":"GenericMockRepository ( id_factory = uuid4 , ** _ ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] A repository implementation for tests. Uses a dict for storage.","title":"GenericMockRepository"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.__class_getitem__","text":"__class_getitem__ ( item ) Add collection to _collections for the type. Parameters: Name Type Description Default item type [ ModelT ] The type that the class has been parametrized with. required","title":"__class_getitem__()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.add","text":"add ( data , allow_id = False ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required allow_id bool disable the identified object check. False Returns: Type Description ModelT The added instance.","title":"add()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.clear_collection","text":"clear_collection () Empty the collection for repository type.","title":"clear_collection()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.delete","text":"delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"delete()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.filter_collection_by_kwargs","text":"filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {}","title":"filter_collection_by_kwargs()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.get","text":"get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.list","text":"list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied.","title":"list()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.seed_collection","text":"seed_collection ( instances ) Seed the collection for repository type. Parameters: Name Type Description Default instances Iterable [ ModelT ] the instances to be added to the collection. required","title":"seed_collection()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.update","text":"update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"update()"},{"location":"reference/starlite_saqlalchemy/testing/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.upsert","text":"upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/testing/controller_test/","text":"Automated controller testing. ControllerTest \u00b6 ControllerTest ( client , base_path , collection , raw_collection , service_type , monkeypatch , collection_filters = None , ) Standard controller testing utility. Parameters: Name Type Description Default client TestClient Test client instance. required base_path str Path for POST and collection GET requests. required collection Sequence [ orm . Base ] Collection of domain objects. required raw_collection Sequence [ dict [ str , Any ]] Collection of raw representations of domain objects. required service_type type [ Service ] The domain Service object type. required monkeypatch MonkeyPatch Pytest's monkeypatch. required collection_filters dict [ str , Any ] | None Collection filters for GET collection request. None run \u00b6 run () Run the tests. test_get_collection \u00b6 test_get_collection ( with_filters = False ) Test collection endpoint get request. test_member_request \u00b6 test_member_request ( method , service_method , exp_status ) Test member endpoint request.","title":"controller_test"},{"location":"reference/starlite_saqlalchemy/testing/controller_test/#starlite_saqlalchemy.testing.controller_test.ControllerTest","text":"ControllerTest ( client , base_path , collection , raw_collection , service_type , monkeypatch , collection_filters = None , ) Standard controller testing utility. Parameters: Name Type Description Default client TestClient Test client instance. required base_path str Path for POST and collection GET requests. required collection Sequence [ orm . Base ] Collection of domain objects. required raw_collection Sequence [ dict [ str , Any ]] Collection of raw representations of domain objects. required service_type type [ Service ] The domain Service object type. required monkeypatch MonkeyPatch Pytest's monkeypatch. required collection_filters dict [ str , Any ] | None Collection filters for GET collection request. None","title":"ControllerTest"},{"location":"reference/starlite_saqlalchemy/testing/controller_test/#starlite_saqlalchemy.testing.controller_test.ControllerTest.run","text":"run () Run the tests.","title":"run()"},{"location":"reference/starlite_saqlalchemy/testing/controller_test/#starlite_saqlalchemy.testing.controller_test.ControllerTest.test_get_collection","text":"test_get_collection ( with_filters = False ) Test collection endpoint get request.","title":"test_get_collection()"},{"location":"reference/starlite_saqlalchemy/testing/controller_test/#starlite_saqlalchemy.testing.controller_test.ControllerTest.test_member_request","text":"test_member_request ( method , service_method , exp_status ) Test member endpoint request.","title":"test_member_request()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/","text":"A repository implementation for tests. Uses a dict for storage. GenericMockRepository \u00b6 GenericMockRepository ( id_factory = uuid4 , ** _ ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] A repository implementation for tests. Uses a dict for storage. __class_getitem__ classmethod \u00b6 __class_getitem__ ( item ) Add collection to _collections for the type. Parameters: Name Type Description Default item type [ ModelT ] The type that the class has been parametrized with. required add async \u00b6 add ( data , allow_id = False ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required allow_id bool disable the identified object check. False Returns: Type Description ModelT The added instance. clear_collection classmethod \u00b6 clear_collection () Empty the collection for repository type. delete async \u00b6 delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . filter_collection_by_kwargs \u00b6 filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {} get async \u00b6 get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ . list async \u00b6 list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied. seed_collection classmethod \u00b6 seed_collection ( instances ) Seed the collection for repository type. Parameters: Name Type Description Default instances Iterable [ ModelT ] the instances to be added to the collection. required update async \u00b6 update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data . upsert async \u00b6 upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"generic_mock_repository"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository","text":"GenericMockRepository ( id_factory = uuid4 , ** _ ) Bases: AbstractRepository [ ModelT ] , Generic [ ModelT ] A repository implementation for tests. Uses a dict for storage.","title":"GenericMockRepository"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.__class_getitem__","text":"__class_getitem__ ( item ) Add collection to _collections for the type. Parameters: Name Type Description Default item type [ ModelT ] The type that the class has been parametrized with. required","title":"__class_getitem__()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.add","text":"add ( data , allow_id = False ) Add data to the collection. Parameters: Name Type Description Default data ModelT Instance to be added to the collection. required allow_id bool disable the identified object check. False Returns: Type Description ModelT The added instance.","title":"add()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.clear_collection","text":"clear_collection () Empty the collection for repository type.","title":"clear_collection()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.delete","text":"delete ( id_ ) Delete instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of instance to be deleted. required Returns: Type Description ModelT The deleted instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"delete()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.filter_collection_by_kwargs","text":"filter_collection_by_kwargs ( ** kwargs ) Filter the collection by kwargs. Parameters: Name Type Description Default **kwargs Any key/value pairs such that objects remaining in the collection after filtering have the property that their attribute named key has value equal to value . {}","title":"filter_collection_by_kwargs()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.get","text":"get ( id_ ) Get instance identified by id_ . Parameters: Name Type Description Default id_ Any Identifier of the instance to be retrieved. required Returns: Type Description ModelT The retrieved instance. Raises: Type Description RepositoryNotFoundException If no instance found identified by id_ .","title":"get()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.list","text":"list ( * filters , ** kwargs ) Get a list of instances, optionally filtered. Parameters: Name Type Description Default *filters FilterTypes Types for specific filtering operations. () **kwargs Any Instance attribute value filters. {} Returns: Type Description list [ ModelT ] The list of instances, after filtering applied.","title":"list()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.seed_collection","text":"seed_collection ( instances ) Seed the collection for repository type. Parameters: Name Type Description Default instances Iterable [ ModelT ] the instances to be added to the collection. required","title":"seed_collection()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.update","text":"update ( data ) Update instance with the attribute values present on data . Parameters: Name Type Description Default data ModelT An instance that should have a value for self.id_attribute that exists in the collection. required Returns: Type Description ModelT The updated instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"update()"},{"location":"reference/starlite_saqlalchemy/testing/generic_mock_repository/#starlite_saqlalchemy.testing.generic_mock_repository.GenericMockRepository.upsert","text":"upsert ( data ) Update or create instance. Updates instance with the attribute values present on data , or creates a new instance if one doesn't exist. Parameters: Name Type Description Default data ModelT Instance to update existing, or be created. Identifier used to determine if an existing instance exists is the value of an attribute on data named as value of self.id_attribute . required Returns: Type Description ModelT The updated or created instance. Raises: Type Description RepositoryNotFoundException If no instance found with same identifier as data .","title":"upsert()"},{"location":"reference/starlite_saqlalchemy/testing/modify_settings/","text":"A context manager to support patching application settings. modify_settings \u00b6 modify_settings ( * update ) Context manager that modify the desired settings and restore them on exit. assert settings.app.ENVIRONMENT = \"local\" with modify_settings((settings.app, {\"ENVIRONMENT\": \"prod\"})): assert settings.app.ENVIRONMENT == \"prod\" assert settings.app.ENVIRONMENT == \"local\"","title":"modify_settings"},{"location":"reference/starlite_saqlalchemy/testing/modify_settings/#starlite_saqlalchemy.testing.modify_settings.modify_settings","text":"modify_settings ( * update ) Context manager that modify the desired settings and restore them on exit. assert settings.app.ENVIRONMENT = \"local\" with modify_settings((settings.app, {\"ENVIRONMENT\": \"prod\"})): assert settings.app.ENVIRONMENT == \"prod\" assert settings.app.ENVIRONMENT == \"local\"","title":"modify_settings()"},{"location":"testing/pytest_plugin/","text":"Pytest Plugin \u00b6 The nature of applications built with the starlite-saqlalchemy pattern is that they rely heavily on connected services. Abstraction of PostgreSQL and Redis connectivity boilerplate is a nice convenience, however to successfully patch the application for testing requires deeper knowledge of the implementation than would be otherwise necessary. So, starlite-saqlalchemy ships with a selection of pytest fixtures that are often necessary when building applications such as these. app \u00b6 The app fixture provides an instance of a Starlite application. from __future__ import annotations from starlite import Starlite def test_app_fixture ( app : Starlite ) -> None : assert isinstance ( app , Starlite ) The value of Pytest ini option, test_app is used to determine the application to load. # pyproject.toml [tool.pytest.ini_options] test_app = \"app.main:create_app\" If no value is configured for the test_app ini option, the default location of \"app.main:create_app\" is searched. The value of the test_app ini option can either point to an application factory or Starlite instance. If the object found at the import path is not a Starlite instance, the fixture assumes it is an application factory, and will call the object and return the response. The value of test_app is resolved using the uvicorn import_from_string() function, so it supports the same format as uvicorn supports for its app and factory parameters. client \u00b6 A starlite.testing.TestClient instance, wired to the same application that is produced by the app fixture. cap_logger \u00b6 The cap_logger fixture provides an instance of structlog.testing.CapturingLogger . from __future__ import annotations from typing import TYPE_CHECKING from structlog.testing import CapturedCall if TYPE_CHECKING : from structlog.testing import CapturingLogger def test_app_fixture ( cap_logger : CapturingLogger ) -> None : cap_logger . info ( \"hello\" ) cap_logger . info ( \"hello\" , when = \"again\" ) assert cap_logger . calls == [ CapturedCall ( method_name = \"info\" , args = ( \"hello\" ,), kwargs = {}), CapturedCall ( method_name = \"info\" , args = ( \"hello\" ,), kwargs = { \"when\" : \"again\" }), ] The cap_logger fixture will capture any structlog calls made by the starlite application or the SAQ worker, so that they can be inspected as part of tests. from __future__ import annotations from typing import TYPE_CHECKING from httpx import AsyncClient if TYPE_CHECKING : from starlite import Starlite from structlog.testing import CapturingLogger async def test_health_logging_skipped ( app : Starlite , cap_logger : CapturingLogger ) -> None : \"\"\"Test that calls to the health check route are not logged.\"\"\" async with AsyncClient ( app = app , base_url = \"http://testserver\" ) as client : response = await client . get ( \"/health\" ) assert response . status_code == 200 assert [] == cap_logger . calls is_unit_test \u00b6 The is_unit_test fixture returns a bool that indicates if the test suite believes it is running a unit test, or an integration test. To determine this, we compare the path of the running test to the value of the Pytest ini option unit_test_pattern , which by default is \"^.*/tests/unit/.*$\" . This fixture is used to make fixtures behave differently between unit and integration test contexts. _patch_http_close \u00b6 This is an autouse fixture , that prevents HTTP clients that are defined in the global scope from being closed. The application is configured to close all instantiated HTTP clients on app shutdown, however when apps are defined in a global/class scope, a test that runs after the first application shutdown in the test suite would fail. _patch_sqlalchemy_plugin \u00b6 This is an autouse fixture , that mocks out the on_shutdown method of the SQLAlchemy config object for unit tests. _patch_worker \u00b6 This is an autouse fixture , that mocks out the on_app_startup and stop methods of worker.Worker type for unit tests.","title":"Pytest Plugin"},{"location":"testing/pytest_plugin/#pytest-plugin","text":"The nature of applications built with the starlite-saqlalchemy pattern is that they rely heavily on connected services. Abstraction of PostgreSQL and Redis connectivity boilerplate is a nice convenience, however to successfully patch the application for testing requires deeper knowledge of the implementation than would be otherwise necessary. So, starlite-saqlalchemy ships with a selection of pytest fixtures that are often necessary when building applications such as these.","title":"Pytest Plugin"},{"location":"testing/pytest_plugin/#app","text":"The app fixture provides an instance of a Starlite application. from __future__ import annotations from starlite import Starlite def test_app_fixture ( app : Starlite ) -> None : assert isinstance ( app , Starlite ) The value of Pytest ini option, test_app is used to determine the application to load. # pyproject.toml [tool.pytest.ini_options] test_app = \"app.main:create_app\" If no value is configured for the test_app ini option, the default location of \"app.main:create_app\" is searched. The value of the test_app ini option can either point to an application factory or Starlite instance. If the object found at the import path is not a Starlite instance, the fixture assumes it is an application factory, and will call the object and return the response. The value of test_app is resolved using the uvicorn import_from_string() function, so it supports the same format as uvicorn supports for its app and factory parameters.","title":"app"},{"location":"testing/pytest_plugin/#client","text":"A starlite.testing.TestClient instance, wired to the same application that is produced by the app fixture.","title":"client"},{"location":"testing/pytest_plugin/#cap_logger","text":"The cap_logger fixture provides an instance of structlog.testing.CapturingLogger . from __future__ import annotations from typing import TYPE_CHECKING from structlog.testing import CapturedCall if TYPE_CHECKING : from structlog.testing import CapturingLogger def test_app_fixture ( cap_logger : CapturingLogger ) -> None : cap_logger . info ( \"hello\" ) cap_logger . info ( \"hello\" , when = \"again\" ) assert cap_logger . calls == [ CapturedCall ( method_name = \"info\" , args = ( \"hello\" ,), kwargs = {}), CapturedCall ( method_name = \"info\" , args = ( \"hello\" ,), kwargs = { \"when\" : \"again\" }), ] The cap_logger fixture will capture any structlog calls made by the starlite application or the SAQ worker, so that they can be inspected as part of tests. from __future__ import annotations from typing import TYPE_CHECKING from httpx import AsyncClient if TYPE_CHECKING : from starlite import Starlite from structlog.testing import CapturingLogger async def test_health_logging_skipped ( app : Starlite , cap_logger : CapturingLogger ) -> None : \"\"\"Test that calls to the health check route are not logged.\"\"\" async with AsyncClient ( app = app , base_url = \"http://testserver\" ) as client : response = await client . get ( \"/health\" ) assert response . status_code == 200 assert [] == cap_logger . calls","title":"cap_logger"},{"location":"testing/pytest_plugin/#is_unit_test","text":"The is_unit_test fixture returns a bool that indicates if the test suite believes it is running a unit test, or an integration test. To determine this, we compare the path of the running test to the value of the Pytest ini option unit_test_pattern , which by default is \"^.*/tests/unit/.*$\" . This fixture is used to make fixtures behave differently between unit and integration test contexts.","title":"is_unit_test"},{"location":"testing/pytest_plugin/#_patch_http_close","text":"This is an autouse fixture , that prevents HTTP clients that are defined in the global scope from being closed. The application is configured to close all instantiated HTTP clients on app shutdown, however when apps are defined in a global/class scope, a test that runs after the first application shutdown in the test suite would fail.","title":"_patch_http_close"},{"location":"testing/pytest_plugin/#_patch_sqlalchemy_plugin","text":"This is an autouse fixture , that mocks out the on_shutdown method of the SQLAlchemy config object for unit tests.","title":"_patch_sqlalchemy_plugin"},{"location":"testing/pytest_plugin/#_patch_worker","text":"This is an autouse fixture , that mocks out the on_app_startup and stop methods of worker.Worker type for unit tests.","title":"_patch_worker"}]}